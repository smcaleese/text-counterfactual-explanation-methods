{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from config import RESULTS\n",
    "\n",
    "now = datetime.today().strftime(\"%d%m%Y %H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = glob(RESULTS + 'counterfactuals_*seed-*.json')\n",
    "candidates = [sorted(glob(RESULTS + f'counterfactuals_{dataset}_{model}_top-5_*_counterfactualgan.json'), reverse=dataset != 'hatespeech')[:5]\n",
    "              for model in ('whitebox', 'infersent', 'bert')\n",
    "              for dataset in ('sst', 'hatespeech', 'snli')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_ = pd.concat([pd.read_json(f) for f in baselines + [l for li in candidates for l in li]]) \\\n",
    "      .sort_values(by=['dataset', 'model', 'explanation_method']) \\\n",
    "      .reset_index(drop=True)\n",
    "c_.to_json(RESULTS + f'counterfactuals-{now}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">hatespeech</th>\n",
       "      <th colspan=\"3\" halign=\"left\">sst</th>\n",
       "      <th colspan=\"3\" halign=\"left\">snli</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explanation_method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sedc</th>\n",
       "      <td>0.169 + 0.028</td>\n",
       "      <td>0.115 + 0.001</td>\n",
       "      <td>0.122 + 0.001</td>\n",
       "      <td>0.629 + 0.009</td>\n",
       "      <td>0.683 + 0.020</td>\n",
       "      <td>0.652 + 0.015</td>\n",
       "      <td>0.407 + 0.001</td>\n",
       "      <td>0.398 + 0.003</td>\n",
       "      <td>0.477 + 0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwwsantonym</th>\n",
       "      <td>0.169 + 0.002</td>\n",
       "      <td>0.124 + 0.002</td>\n",
       "      <td>0.130 + 0.002</td>\n",
       "      <td>0.694 + 0.010</td>\n",
       "      <td>0.686 + 0.043</td>\n",
       "      <td>0.641 + 0.014</td>\n",
       "      <td>0.400 + 0.002</td>\n",
       "      <td>0.408 + 0.004</td>\n",
       "      <td>0.493 + 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebert</th>\n",
       "      <td>0.229 + 0.001</td>\n",
       "      <td>0.239 + 0.002</td>\n",
       "      <td>0.243 + 0.001</td>\n",
       "      <td>0.465 + 0.010</td>\n",
       "      <td>0.478 + 0.015</td>\n",
       "      <td>0.440 + 0.018</td>\n",
       "      <td>0.330 + 0.004</td>\n",
       "      <td>0.313 + 0.001</td>\n",
       "      <td>0.313 + 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textfooler</th>\n",
       "      <td>0.132 + 0.002</td>\n",
       "      <td>0.223 + 0.002</td>\n",
       "      <td>0.235 + 0.002</td>\n",
       "      <td>0.643 + 0.014</td>\n",
       "      <td>0.645 + 0.012</td>\n",
       "      <td>0.574 + 0.019</td>\n",
       "      <td>0.322 + 0.015</td>\n",
       "      <td>0.244 + 0.006</td>\n",
       "      <td>0.271 + 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counterfactualgan (top-5)</th>\n",
       "      <td>0.136 + 0.002</td>\n",
       "      <td>0.097 + 0.031</td>\n",
       "      <td>0.154 + 0.044</td>\n",
       "      <td>0.798 + 0.015</td>\n",
       "      <td>0.890 + 0.010</td>\n",
       "      <td>0.902 + 0.020</td>\n",
       "      <td>0.487 + 0.049</td>\n",
       "      <td>0.534 + 0.028</td>\n",
       "      <td>0.462 + 0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                       hatespeech                                \\\n",
       "model                           whitebox      infersent           bert   \n",
       "explanation_method                                                       \n",
       "sedc                       0.169 + 0.028  0.115 + 0.001  0.122 + 0.001   \n",
       "pwwsantonym                0.169 + 0.002  0.124 + 0.002  0.130 + 0.002   \n",
       "ebert                      0.229 + 0.001  0.239 + 0.002  0.243 + 0.001   \n",
       "textfooler                 0.132 + 0.002  0.223 + 0.002  0.235 + 0.002   \n",
       "counterfactualgan (top-5)  0.136 + 0.002  0.097 + 0.031  0.154 + 0.044   \n",
       "\n",
       "dataset                              sst                                \\\n",
       "model                           whitebox      infersent           bert   \n",
       "explanation_method                                                       \n",
       "sedc                       0.629 + 0.009  0.683 + 0.020  0.652 + 0.015   \n",
       "pwwsantonym                0.694 + 0.010  0.686 + 0.043  0.641 + 0.014   \n",
       "ebert                      0.465 + 0.010  0.478 + 0.015  0.440 + 0.018   \n",
       "textfooler                 0.643 + 0.014  0.645 + 0.012  0.574 + 0.019   \n",
       "counterfactualgan (top-5)  0.798 + 0.015  0.890 + 0.010  0.902 + 0.020   \n",
       "\n",
       "dataset                             snli                                \n",
       "model                           whitebox      infersent           bert  \n",
       "explanation_method                                                      \n",
       "sedc                       0.407 + 0.001  0.398 + 0.003  0.477 + 0.003  \n",
       "pwwsantonym                0.400 + 0.002  0.408 + 0.004  0.493 + 0.002  \n",
       "ebert                      0.330 + 0.004  0.313 + 0.001  0.313 + 0.002  \n",
       "textfooler                 0.322 + 0.015  0.244 + 0.006  0.271 + 0.008  \n",
       "counterfactualgan (top-5)  0.487 + 0.049  0.534 + 0.028  0.462 + 0.008  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid = c_.groupby(['model', 'dataset', 'explanation_method'])['fidelity']\n",
    "fid = pd.concat([fid.mean(), fid.std()], axis=1).apply(lambda s: f'{s[0]:.3f} + {s[1]:.3f}', axis=1) \\\n",
    "        .unstack(2).T.swaplevel(0, 1, 1) \\\n",
    "        .sort_index(axis=1, key=lambda x: x.map({'hatespeech':0, 'whitebox':0, 'sst': 1, 'infersent': 1, 'snli': 2, 'bert': 2})) \\\n",
    "        .sort_index(axis=0, key=lambda x: x.map({'sedc': 0, 'pwwsantonym': 1, 'ebert': 2, 'textfooler': 3, 'counterfactualgan (top-5)': 4}))\n",
    "fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{3}{l}{hatespeech} & \\multicolumn{3}{l}{sst} & \\multicolumn{3}{l}{snli} \\\\\n",
      "model &       whitebox &      infersent &           bert &       whitebox &      infersent &           bert &       whitebox &      infersent &           bert \\\\\n",
      "explanation\\_method        &                &                &                &                &                &                &                &                &                \\\\\n",
      "\\midrule\n",
      "sedc                      &  .169\\rpm .028 &  .115\\rpm .001 &  .122\\rpm .001 &  .629\\rpm .009 &  .683\\rpm .020 &  .652\\rpm .015 &  .407\\rpm .001 &  .398\\rpm .003 &  .477\\rpm .003 \\\\\n",
      "pwwsantonym               &  .169\\rpm .002 &  .124\\rpm .002 &  .130\\rpm .002 &  .694\\rpm .010 &  .686\\rpm .043 &  .641\\rpm .014 &  .400\\rpm .002 &  .408\\rpm .004 &  .493\\rpm .002 \\\\\n",
      "ebert                     &  .229\\rpm .001 &  .239\\rpm .002 &  .243\\rpm .001 &  .465\\rpm .010 &  .478\\rpm .015 &  .440\\rpm .018 &  .330\\rpm .004 &  .313\\rpm .001 &  .313\\rpm .002 \\\\\n",
      "textfooler                &  .132\\rpm .002 &  .223\\rpm .002 &  .235\\rpm .002 &  .643\\rpm .014 &  .645\\rpm .012 &  .574\\rpm .019 &  .322\\rpm .015 &  .244\\rpm .006 &  .271\\rpm .008 \\\\\n",
      "counterfactualgan (top-5) &  .136\\rpm .002 &  .097\\rpm .031 &  .154\\rpm .044 &  .798\\rpm .015 &  .890\\rpm .010 &  .902\\rpm .020 &  .487\\rpm .049 &  .534\\rpm .028 &  .462\\rpm .008 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fid.to_latex().replace(' + ', '\\\\rpm ').replace(' 0.', ' .'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">hatespeech</th>\n",
       "      <th colspan=\"3\" halign=\"left\">sst</th>\n",
       "      <th colspan=\"3\" halign=\"left\">snli</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explanation_method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sedc</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwwsantonym</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebert</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textfooler</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counterfactualgan (top-5)</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                   hatespeech                      sst                  \\\n",
       "model                       whitebox infersent  bert whitebox infersent  bert   \n",
       "explanation_method                                                              \n",
       "sedc                            0.20      0.19  0.19     0.20      0.20  0.21   \n",
       "pwwsantonym                     0.17      0.18  0.18     0.18      0.17  0.18   \n",
       "ebert                           0.12      0.12  0.12     0.12      0.12  0.12   \n",
       "textfooler                      0.21      0.07  0.07     0.21      0.26  0.20   \n",
       "counterfactualgan (top-5)       0.32      0.37  0.21     0.32      0.37  0.41   \n",
       "\n",
       "dataset                       snli                  \n",
       "model                     whitebox infersent  bert  \n",
       "explanation_method                                  \n",
       "sedc                          0.10      0.09  0.09  \n",
       "pwwsantonym                   0.11      0.12  0.10  \n",
       "ebert                         0.06      0.08  0.06  \n",
       "textfooler                    0.22      0.24  0.27  \n",
       "counterfactualgan (top-5)     0.11      0.36  0.37  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem = c_.groupby(['model', 'dataset', 'explanation_method'])['semantic']\n",
    "sem = pd.concat([1.0 - sem.mean(), sem.std()], axis=1).apply(lambda s: f'{s[0]:.2f}', axis=1) \\\n",
    "        .unstack(2).T.swaplevel(0, 1, 1) \\\n",
    "        .sort_index(axis=1, key=lambda x: x.map({'hatespeech':0, 'whitebox':0, 'sst': 1, 'infersent': 1, 'snli': 2, 'bert': 2})) \\\n",
    "        .sort_index(axis=0, key=lambda x: x.map({'sedc': 0, 'pwwsantonym': 1, 'ebert': 2, 'textfooler': 3, 'counterfactualgan (top-5)': 4}))\n",
    "sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{3}{l}{hatespeech} & \\multicolumn{3}{l}{sst} & \\multicolumn{3}{l}{snli} \\\\\n",
      "model &   whitebox & infersent &  bert & whitebox & infersent &  bert & whitebox & infersent &  bert \\\\\n",
      "explanation\\_method        &            &           &       &          &           &       &          &           &       \\\\\n",
      "\\midrule\n",
      "sedc                      &       .20 &      .19 &  .19 &     .20 &      .20 &  .21 &     .10 &      .09 &  .09 \\\\\n",
      "pwwsantonym               &       .17 &      .18 &  .18 &     .18 &      .17 &  .18 &     .11 &      .12 &  .10 \\\\\n",
      "ebert                     &       .12 &      .12 &  .12 &     .12 &      .12 &  .12 &     .06 &      .08 &  .06 \\\\\n",
      "textfooler                &       .21 &      .07 &  .07 &     .21 &      .26 &  .20 &     .22 &      .24 &  .27 \\\\\n",
      "counterfactualgan (top-5) &       .32 &      .37 &  .21 &     .32 &      .37 &  .41 &     .11 &      .36 &  .37 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sem.to_latex().replace(' + ', '\\\\rpm ').replace(' 0.', ' .'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset     explanation_method       \n",
       "hatespeech  counterfactualgan (top-5)     0.384241\n",
       "            ebert                         5.486953\n",
       "            pwwsantonym                   1.041880\n",
       "            sedc                          0.983457\n",
       "            textfooler                   24.690040\n",
       "snli        counterfactualgan (top-5)     1.385634\n",
       "            ebert                         9.104822\n",
       "            pwwsantonym                   2.732665\n",
       "            sedc                          2.533796\n",
       "            textfooler                   16.237449\n",
       "sst         counterfactualgan (top-5)     0.167270\n",
       "            ebert                         0.788701\n",
       "            pwwsantonym                   0.246023\n",
       "            sedc                          0.210332\n",
       "            textfooler                   24.360862\n",
       "Name: inference_time, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = c_.groupby(['dataset', 'explanation_method'])['inference_time'].mean() / 60.\n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_percentage(row):\n",
    "    lengths = {'hatespeech': 19.1, 'sst': 19.2, 'snli': 20.3}[row['dataset']]\n",
    "    return np.mean(np.array(row['X_sim'])) / lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_['new_dis'] = c_[['dataset', 'X_sim']].apply(similarity_percentage, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">hatespeech</th>\n",
       "      <th colspan=\"3\" halign=\"left\">sst</th>\n",
       "      <th colspan=\"3\" halign=\"left\">snli</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "      <th>whitebox</th>\n",
       "      <th>infersent</th>\n",
       "      <th>bert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explanation_method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ebert</th>\n",
       "      <td>0.208 + 0.000</td>\n",
       "      <td>0.208 + 0.000</td>\n",
       "      <td>0.208 + 0.001</td>\n",
       "      <td>0.068 + 0.001</td>\n",
       "      <td>0.067 + 0.001</td>\n",
       "      <td>0.067 + 0.000</td>\n",
       "      <td>0.759 + 0.000</td>\n",
       "      <td>0.759 + 0.000</td>\n",
       "      <td>0.759 + 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counterfactualgan (top-5)</th>\n",
       "      <td>0.613 + 0.034</td>\n",
       "      <td>0.915 + 0.311</td>\n",
       "      <td>0.344 + 0.420</td>\n",
       "      <td>0.499 + 0.285</td>\n",
       "      <td>0.630 + 0.057</td>\n",
       "      <td>0.690 + 0.007</td>\n",
       "      <td>0.488 + 0.052</td>\n",
       "      <td>1.015 + 0.127</td>\n",
       "      <td>0.945 + 0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwwsantonym</th>\n",
       "      <td>0.155 + 0.019</td>\n",
       "      <td>0.167 + 0.001</td>\n",
       "      <td>0.162 + 0.001</td>\n",
       "      <td>0.166 + 0.001</td>\n",
       "      <td>0.143 + 0.013</td>\n",
       "      <td>0.153 + 0.002</td>\n",
       "      <td>0.763 + 0.000</td>\n",
       "      <td>0.757 + 0.001</td>\n",
       "      <td>0.756 + 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sedc</th>\n",
       "      <td>0.337 + 0.288</td>\n",
       "      <td>0.208 + 0.001</td>\n",
       "      <td>0.200 + 0.002</td>\n",
       "      <td>0.195 + 0.001</td>\n",
       "      <td>0.187 + 0.004</td>\n",
       "      <td>0.205 + 0.002</td>\n",
       "      <td>0.755 + 0.001</td>\n",
       "      <td>0.743 + 0.001</td>\n",
       "      <td>0.745 + 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textfooler</th>\n",
       "      <td>0.245 + 0.000</td>\n",
       "      <td>0.006 + 0.000</td>\n",
       "      <td>0.006 + 0.000</td>\n",
       "      <td>0.348 + 0.000</td>\n",
       "      <td>0.370 + 0.000</td>\n",
       "      <td>0.268 + 0.000</td>\n",
       "      <td>0.991 + 0.000</td>\n",
       "      <td>0.999 + 0.000</td>\n",
       "      <td>1.005 + 0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                       hatespeech                                \\\n",
       "model                           whitebox      infersent           bert   \n",
       "explanation_method                                                       \n",
       "ebert                      0.208 + 0.000  0.208 + 0.000  0.208 + 0.001   \n",
       "counterfactualgan (top-5)  0.613 + 0.034  0.915 + 0.311  0.344 + 0.420   \n",
       "pwwsantonym                0.155 + 0.019  0.167 + 0.001  0.162 + 0.001   \n",
       "sedc                       0.337 + 0.288  0.208 + 0.001  0.200 + 0.002   \n",
       "textfooler                 0.245 + 0.000  0.006 + 0.000  0.006 + 0.000   \n",
       "\n",
       "dataset                              sst                                \\\n",
       "model                           whitebox      infersent           bert   \n",
       "explanation_method                                                       \n",
       "ebert                      0.068 + 0.001  0.067 + 0.001  0.067 + 0.000   \n",
       "counterfactualgan (top-5)  0.499 + 0.285  0.630 + 0.057  0.690 + 0.007   \n",
       "pwwsantonym                0.166 + 0.001  0.143 + 0.013  0.153 + 0.002   \n",
       "sedc                       0.195 + 0.001  0.187 + 0.004  0.205 + 0.002   \n",
       "textfooler                 0.348 + 0.000  0.370 + 0.000  0.268 + 0.000   \n",
       "\n",
       "dataset                             snli                                \n",
       "model                           whitebox      infersent           bert  \n",
       "explanation_method                                                      \n",
       "ebert                      0.759 + 0.000  0.759 + 0.000  0.759 + 0.000  \n",
       "counterfactualgan (top-5)  0.488 + 0.052  1.015 + 0.127  0.945 + 0.126  \n",
       "pwwsantonym                0.763 + 0.000  0.757 + 0.001  0.756 + 0.000  \n",
       "sedc                       0.755 + 0.001  0.743 + 0.001  0.745 + 0.000  \n",
       "textfooler                 0.991 + 0.000  0.999 + 0.000  1.005 + 0.000  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis = c_.groupby(['model', 'dataset', 'explanation_method'])['new_dis']\n",
    "dis = pd.concat([dis.mean(), dis.std()], axis=1).apply(lambda s: f'{s[0]:.3f} + {s[1]:.3f}', axis=1) \\\n",
    "        .unstack(2).T.swaplevel(0, 1, 1) \\\n",
    "        .sort_index(axis=1, key=lambda x: x.map({'hatespeech':0, 'whitebox':0, 'sst': 1, 'infersent': 1, 'snli': 2, 'bert': 2})) \\\n",
    "        .sort_index(axis=0, key=lambda x: x.map({'lfo': 0, 'wordnet': 1, 'ebert': 2}))\n",
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{3}{l}{hatespeech} & \\multicolumn{3}{l}{sst} & \\multicolumn{3}{l}{snli} \\\\\n",
      "model &       whitebox &      infersent &           bert &       whitebox &      infersent &           bert &       whitebox &      infersent &           bert \\\\\n",
      "explanation\\_method        &                &                &                &                &                &                &                &                &                \\\\\n",
      "\\midrule\n",
      "ebert                     &  .208\\rpm .000 &  .208\\rpm .000 &  .208\\rpm .001 &  .068\\rpm .001 &  .067\\rpm .001 &  .067\\rpm .000 &  .759\\rpm .000 &  .759\\rpm .000 &  .759\\rpm .000 \\\\\n",
      "counterfactualgan (top-5) &  .613\\rpm .034 &  .915\\rpm .311 &  .344\\rpm .420 &  .499\\rpm .285 &  .630\\rpm .057 &  .690\\rpm .007 &  .488\\rpm .052 &  1.015\\rpm .127 &  .945\\rpm .126 \\\\\n",
      "pwwsantonym               &  .155\\rpm .019 &  .167\\rpm .001 &  .162\\rpm .001 &  .166\\rpm .001 &  .143\\rpm .013 &  .153\\rpm .002 &  .763\\rpm .000 &  .757\\rpm .001 &  .756\\rpm .000 \\\\\n",
      "sedc                      &  .337\\rpm .288 &  .208\\rpm .001 &  .200\\rpm .002 &  .195\\rpm .001 &  .187\\rpm .004 &  .205\\rpm .002 &  .755\\rpm .001 &  .743\\rpm .001 &  .745\\rpm .000 \\\\\n",
      "textfooler                &  .245\\rpm .000 &  .006\\rpm .000 &  .006\\rpm .000 &  .348\\rpm .000 &  .370\\rpm .000 &  .268\\rpm .000 &  .991\\rpm .000 &  .999\\rpm .000 &  1.005\\rpm .000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dis.to_latex().replace(' + ', '\\\\rpm ').replace(' 0.', ' .'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictive_model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>performance</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whitebox</td>\n",
       "      <td>Hatespeech</td>\n",
       "      <td>{'mse': 0.0877286064252976}</td>\n",
       "      <td>whitebox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>infersent</td>\n",
       "      <td>Hatespeech</td>\n",
       "      <td>{'mse': 0.1265283226966858}</td>\n",
       "      <td>infersent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>Hatespeech</td>\n",
       "      <td>{'mse': 0.1222558245062828}</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whitebox</td>\n",
       "      <td>SST</td>\n",
       "      <td>{'f1_score': 0.6790986790986792}</td>\n",
       "      <td>whitebox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>infersent</td>\n",
       "      <td>SST</td>\n",
       "      <td>{'f1_score': 0.7974686622619629}</td>\n",
       "      <td>infersent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>SST</td>\n",
       "      <td>{'f1_score': 0.8833869099617004}</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictive_model     dataset                       performance      model\n",
       "0         whitebox  Hatespeech       {'mse': 0.0877286064252976}   whitebox\n",
       "1        infersent  Hatespeech       {'mse': 0.1265283226966858}  infersent\n",
       "2             bert  Hatespeech       {'mse': 0.1222558245062828}       bert\n",
       "0         whitebox         SST  {'f1_score': 0.6790986790986792}   whitebox\n",
       "1        infersent         SST  {'f1_score': 0.7974686622619629}  infersent\n",
       "2             bert         SST  {'f1_score': 0.8833869099617004}       bert"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ = pd.concat([pd.read_csv(f) for f in glob(RESULTS + '/performance_*.csv')])\n",
    "p_.to_csv(RESULTS + f'performance-{now}.csv', index=None)\n",
    "p_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} & predictive\\_model &     dataset &                       performance &      model \\\\\n",
      "\\midrule\n",
      "0 &         whitebox &  Hatespeech &       \\{'mse': 0.0877286064252976\\} &   whitebox \\\\\n",
      "1 &        infersent &  Hatespeech &       \\{'mse': 0.1265283226966858\\} &  infersent \\\\\n",
      "2 &             bert &  Hatespeech &       \\{'mse': 0.1222558245062828\\} &       bert \\\\\n",
      "0 &         whitebox &         SST &  \\{'f1\\_score': 0.6790986790986792\\} &   whitebox \\\\\n",
      "1 &        infersent &         SST &  \\{'f1\\_score': 0.7974686622619629\\} &  infersent \\\\\n",
      "2 &             bert &         SST &  \\{'f1\\_score': 0.8833869099617004\\} &       bert \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p_.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDs for human experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hatespeech\n",
    "idx = [179, 182, 359, 380, 404, 859, 886, 1075, 1616, 1643, 1849,\n",
    "       1889, 1950, 1981, 2299, 2429, 2959, 2974, 3047, 3131, 3365,\n",
    "       3415, 3521, 3595, 3638, 3851, 3882, 4095, 4118, 4141]\n",
    "\n",
    "# SST\n",
    "idx = [10, 23, 36, 90, 93, 94, 126, 136, 160, 180, 202,\n",
    "       244, 245, 266, 279, 298, 319, 431, 453, 484, 589,\n",
    "       642, 652, 842, 957, 1117, 1149, 1230, 1304, 1327]\n",
    "\n",
    "# SNLI\n",
    "idx = [180, 257, 364, 415, 550, 662, 746, 781, 1289, 2039, 2483,\n",
    "       2584, 2886, 4311, 4323, 4792, 5507, 6168, 6206, 6390, 6513,\n",
    "       6689, 6952, 7120, 7464, 7836, 8050, 8613, 8699, 9187]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "75c0957e41c7ffe43c62d252fc6cfb7ad68a4619934356dee1df9125adce8c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
