{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Mount Google Drive and clone the repository containing the methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUgYxHsWZU8y",
        "outputId": "4254c890-6bd2-4194-c3cc-c99744f2d96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GitHub username: smcaleese\n",
            "Enter your GitHub personal access token: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "\n",
        "github_username = input(\"Enter your GitHub username: \")\n",
        "github_token = getpass.getpass(\"Enter your GitHub personal access token: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPOKvD_RafHj",
        "outputId": "96ffda6e-c3e6-466a-d559-0a2b44931081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'masters-thesis-code'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 110 (delta 2), reused 110 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 2.53 MiB | 7.05 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ],
      "source": [
        "repo_name = \"smcaleese/masters-thesis-code\"\n",
        "!git clone https://{github_username}:{github_token}@github.com/{repo_name}.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "EDPv3DJ8cER4",
        "outputId": "04fbecf9-3acc-4856-de56-f2c2d36c60a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'masters-thesis-code/CLOSS'\n",
            "/content/masters-thesis-code\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/masters-thesis-code'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd masters-thesis-code\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get input\n",
        "\n",
        "Download the IMDB dataset, clean the sentences, and create a list of input sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/smcaleese/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading readme: 100%|██████████| 7.81k/7.81k [00:00<00:00, 20.4MB/s]\n",
            "Downloading data: 100%|██████████| 21.0M/21.0M [00:05<00:00, 4.12MB/s]\n",
            "Downloading data: 100%|██████████| 20.5M/20.5M [00:02<00:00, 9.23MB/s]\n",
            "Downloading data: 100%|██████████| 42.0M/42.0M [00:03<00:00, 11.6MB/s]\n",
            "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 436270.44 examples/s]\n",
            "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 529068.13 examples/s]\n",
            "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 310628.90 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"This movie was sadly under-promoted but proved to be truly exceptional. Entering the theatre I knew nothing about the film except that a friend wanted to see it.<br /><br />I was caught off guard with the high quality of the film. I couldn't image Ashton Kutcher in a serious role, but his performance truly exemplified his character. This movie is exceptional and deserves our monetary support, unlike so many other movies. It does not come lightly for me to recommend any movie, but in this case I highly recommend that everyone see it.<br /><br />This films is Truly Exceptional!\",\n",
              " 'On a dark, gloomy New Year\\'s Eve night, an ill nurse, her life slowly ebbing away, demands that David Holm be presented to her at once. We don\\'t yet know who David Holm is, or why this nurse wishes to see him, but her only dying wish is to speak with him just one more time. On the other side of the town, nestled comfortably amongst the gravestones of the local cemetery, Holm (Victor Sjöström, who also directed) and two of his drunken associates merrily await the coming of the New Year. \"Here we can tell just when to drink the New Year in,\" exclaims Holm, casting a finger towards the large clock tower that looms through the darkness. Little does he know, however, that he will not be alive to greet it.<br /><br />To pass the time, Holm cheerfully recites a ghost story. He\\'d once had a friend name George, \"a merry fellow\" who was \"smarter than the rest of us.\" On one New Year\\'s Eve several years ago, George has broken up a potentially disastrous brawl, fearing that the final man to draw his last breath before midnight would be condemned to drive the phantom chariot for the next year, doing Death\\'s bidding and collecting the souls of the deceased. \"And, gentlemen, George died last New Year\\'s Eve!\" concludes Holm happily, not bothering to contain his mocking skepticism of the man\\'s beliefs.<br /><br />As fate has it, of course, an unexpected violent encounter results in Holm\\'s death, just on the stroke of midnight. As the man\\'s transparent spirit rises gingerly from his earthly body, he witnesses, to his horror, the distant approach of a phantom carriage. The driver, a frail cloaked figure - a sickle clasped tightly in his hand - steps down from the carriage and approaches. We are astonished to discover that the driver is none other than a decrepit George, preparing to pass on his ghastly duty to this year\\'s successor.<br /><br />Considering the era in which \\'Körkarlen\\' is made, the special effects in this film are absolutely superb. Cinematographer Julius Jaenzon used double-exposure photography to create the eerie, ghostly silhouette of the carriage and its damned driver. Even today, the end result is highly effective. A particularly impressive scene involves the phantom chariot travelling to the ocean floor to retrieve the soul of a drowned man. Another scene, eerily reminiscent of Jack Torrance (Jack Nicholson) in Stanley Kubrick\\'s \\'The Shining,\\' involves Holm breaking down the kitchen door with an axe in order to reach his fleeing wife and children.<br /><br />Genuinely ominous and unsettling in its execution, Victor Sjöström\\'s \\'Körkarlen\\' is a fine work of cinema, successfully portraying Holm\\'s steady alcoholic decline, his inevitable day of judgment, and a final hopeful possibility of redemption.',\n",
              " \"Haines is excellent as the brash cadet who thinks West Point will really amount to something now that he has arrived. Haines displays his easy, goofy comic persona as he takes on West Point and Joan Crawford, the local beauty. Great fun for the first half. And amazingly touching after Haines's character goes too far and nearly gets shunned by fellow cadets. The new, humility-filled Haines get s alast-minute reprieve to play in the bill football game against Navy and, despite a broken arm, wins the game. Great, rousing entertainment by MGM in this Haines formula film, shows Billy at his best. William Bakewell also scores as the skinny follower. The handsome-but-goony character would be played by Clark Gable, Cary Grant, Gary Cooper and others in later decades, another take on the beautiful-but-daffy dames played by Carole Lombard and Marion Davies. West Point is a winner!\",\n",
              " \"This movie states through its protagonist that the world is essentially sadness and pain and those that ignore this have blinders on. One can argue whether this is true or not. But even if you accept this as true, the movie's ending either A) disputes this by saying there can be some good in tragic situations or B) forgets this and uses a cliched montage in order to leave the audience feeling uplifted.<br /><br />That the movie metaphorically acquits its protagonist by presenting him as a sympathetic character despite any evidence for that sympathy shows contempt for the supporting characters who were the most compelling in the film.<br /><br />So what you have in this film is a script that is not consistent in its theme and direction that does not bring the ending into sync with the rest of the film. There are excellent performances given by every member of the cast especially Spacey, Olin, Martin Donovan, and Ann Magnuson. It's a shame that they weren't supported by a better writer/director.\",\n",
              " 'Just saw this movie on opening night. I read some other user comments which convinced me to go see it... I must say, I was not impressed. I\\'m so unimpressed that I feel the need to write this comment to spare some of you people some money.<br /><br />First of all \"The Messengers\" is very predictable, and just not much of a thriller. It might be scary for someone under 13, but it really did nothing for me. The climax was laughable and most of the audience left before the movie\\'s resolution.<br /><br />Furthermore the acting seemed a little superficial. Some of the emotional arguments between the family were less convincing than the sub-par suspense scenes.<br /><br />If you\\'ve seen previews for this movie, then you\\'ve seen most of the best parts and have a strong understanding of the plot. This movie is not worth seeing in the theaters.',\n",
              " \"This episode so far is the best of the series. The story was told perfectly. I especially liked how the writers made it a Desmond episode; it was his best performance to date and he definitely deserved the Emmy for his performance.<br /><br />We had some of our questions answered in this episode, but since the show is called Lost we know there will be more questions brought up too. First the answered: Walt is reunited finally with his father Michael, second, Michael's betrayal is exposed to Jack, Sawyer, Kate, and Hurly and because of this betrayal Kate, Jack, and Sawyer are all taken captive by The Others. This was a great way to end the show.<br /><br />On the other side of the island we see Locke going through a mental breakdown with the button. This leads to another answered question about how the plane really went down. However there are some unanswered questions: first, what happened to Locke, Eko, and Desmond when Desmond turned the failsafe key and what was the deal with the scientists in the Arctic searching for electromagnetic annamolies. Guess we'll find out next season, however great ending to the best show on TV.\",\n",
              " \"This is surely British humour at its best. It tends to grow on you. The first time I watched it I couldn't quite figure out what it was all about but now I can watch the episodes over and over again and enjoy them every time.\",\n",
              " 'Laura Gemser plays a magazine photographer who is sent to Africa for a photo shoot. There she is met by a couple and other swinging couples. They all stay at this huge, very touristy hotel with a gigantic swimming pool. One night they have a pool party complete with \"real live\" native dancers. It\\'s very un-politically correct and very kitschy. Later, Emanuelle finally has her photo shoot, which turns out to be in one of those drive-through, stay-in-your-car safaris (albeit the photography is gorgeous). Throughout the film, Emanuelle is going after every man she meets. The photography is very well done in this film. There are scenes with cascading waterfalls, galloping giraffes and ancient ruins. The film is worth seeing for the soundtrack by Nico Fidenco alone.',\n",
              " 'What a mess--and I\\'m not referring to the \"destruction\" in the title. I could go on about the hackneyed plot, the lousy effects, the (actually notable) cast grimacing as they deliver the worst lines of their careers, etc. I\\'ll just say there weren\\'t any palm trees in Chicago the last time I checked, and leave it at that.<br /><br />Hmmm...need ten lines to get this posted on IMDb.. OK, well, I think a DVD release with outtakes could be interesting. Maybe Dennehy will reveal what favor got called in for him to appear in this thing. Maybe Dianne Weist will show us the bag of money it must have taken to get her involved. Maybe CBS execs will apologize...',\n",
              " 'In 1858 Tolstoy wrote this in his diary: \"The political is not compatible with the artistic, because the former, in order to prove, has to be one-sided.\" This thought from a great mind is applicable to USA The Movie. The film might be read by those with a narrow focus as a 90 minute slam of Bush, Cheney et. al. as well as a ripping of America as an out-of-control imperialistic force that will ultimately be destroyed by its own folly and thirst for power. The more open-minded viewer will take note of the recurring images and themes that make this DVD a testament to postmodernist thought, as the main character breaks up into bits and pieces surrounded by recurring visuals of the natural world contrasted with the man-made constructions; towers, roads, video monitors, radio, vehicles. Above all the ominous threat of wars that have been and are to come smolder throughout. War and rumors of war are what is created, destroyed and recreated on the screen, in our conscious world and in our unconscious minds.']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# first 12,500 are negative and the second 12,500 are positive\n",
        "# you could shuffle all the rows and then sample 100\n",
        "\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "num_samples = 10\n",
        "\n",
        "test_sentences = imdb[\"test\"][\"text\"]\n",
        "random_sentences_subset = random.sample(test_sentences, num_samples)\n",
        "\n",
        "test_labels = imdb[\"test\"][\"label\"]\n",
        "random_labels_subset = random.sample(test_labels, num_samples)\n",
        "\n",
        "random_sentences_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of input sentences: 10\n"
          ]
        }
      ],
      "source": [
        "def get_input_sentences_list(sentences, max_length = 512):\n",
        "    sentences_list = []\n",
        "    for i in range(len(sentences)):\n",
        "        text = sentences[i]\n",
        "        if len(text.split()) > max_length:\n",
        "            continue\n",
        "        text = text.replace(\"<br /><br />\", \" \")\n",
        "        sentences_list.append(text)\n",
        "    return sentences_list\n",
        "\n",
        "input_sentences_list = get_input_sentences_list(random_sentences_subset)\n",
        "print(f\"Number of input sentences: {len(input_sentences_list)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write the sentences to a file named `imdb-input.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(input_sentences_list, columns=[\"original_text\"])\n",
        "df.to_csv(\"./input/input_sentences.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run CLOSS\n",
        "\n",
        "Run the first method on the input sentences and get the output as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Bs0A2HyLcT",
        "outputId": "651017cf-5646-4242-ba60-22193eba3b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "use_hotflip_only   : False\n",
            "use_SVs            : True\n",
            "use_grad_only      : False\n",
            "no_opt_lmh         : False\n",
            "random_logit_matrix: False\n",
            "use_bert           : False\n",
            "use_roberta        : True\n",
            "test_acc           : False\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 192kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 559/559 [00:00<00:00, 3.83MB/s]\n",
            "vocab.json: 100% 798k/798k [00:00<00:00, 1.55MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 878kB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.83MB/s]\n",
            "pytorch_model.bin:  50% 252M/501M [00:16<00:21, 11.5MB/s]"
          ]
        }
      ],
      "source": [
        "# Run CLOSS-RTL on RoBERTa IMDB.\n",
        "# This will NOT retrain the language modeling head, so it will start within 2 minutes.\n",
        "\n",
        "!python3 run_closs.py --dataset imdb --beamwidth 15 --w 5 --K 30 --evaluation closs --model roberta --retrain_epochs 10 --lm_head default --saliency_method norm_grad --log_note ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK0QPPQ1_i94"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
