{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Mount Google Drive and clone the repository containing the methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUgYxHsWZU8y",
        "outputId": "4254c890-6bd2-4194-c3cc-c99744f2d96c"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "github_username = input(\"Enter your GitHub username: \")\n",
        "github_token = getpass.getpass(\"Enter your GitHub personal access token: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPOKvD_RafHj",
        "outputId": "96ffda6e-c3e6-466a-d559-0a2b44931081"
      },
      "outputs": [],
      "source": [
        "repo_name = \"smcaleese/masters-thesis-code\"\n",
        "!git clone https://{github_username}:{github_token}@github.com/{repo_name}.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "EDPv3DJ8cER4",
        "outputId": "04fbecf9-3acc-4856-de56-f2c2d36c60a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'masters-thesis-code'\n",
            "/Users/smcaleese/Documents/masters-thesis-code\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/smcaleese/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/Users/smcaleese/Documents/masters-thesis-code'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd masters-thesis-code\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install necessary dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install transformers datasets textdistance openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download datasets\n",
        "\n",
        "Download the SST-2, QNLI and AG News datasets, clean the sentences, and create a list of input sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_samples = 1000\n",
        "\n",
        "dataset = \"sst_2\"\n",
        "# dataset = \"qnli\"\n",
        "# dataset = \"ag_news\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def format_sentence(sentence, dataset):\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # remove two spaces around a comma:\n",
        "    sentence = re.sub(r\"\\s(')\\s(ve|re|s|t|ll|d)\", r\"\\1\\2\", sentence)\n",
        "\n",
        "    # remove spaces around hyphens:\n",
        "    sentence = re.sub(r\"-\\s-\", \"--\", sentence)\n",
        "    sentence = re.sub(r\"(\\w)\\s-\\s(\\w)\", r\"\\1-\\2\", sentence)\n",
        "\n",
        "    def replace(match):\n",
        "        return match.group(1)\n",
        "\n",
        "    # remove spaces before punctuation and n't:\n",
        "    sentence = re.sub(r\"\\s([.!,?:;')]|n't)\", replace, sentence)\n",
        "\n",
        "    # remove spaces after opening parenthesis:\n",
        "    sentence = re.sub(r\"([(])\\s\", replace, sentence)\n",
        "\n",
        "    if dataset == \"qnli\":\n",
        "        sentence = re.sub(r\"\\s(\\[sep\\])\\s\", \" [SEP] \", sentence)\n",
        "    \n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/smcaleese/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "if dataset == \"sst_2\":\n",
        "    sst = load_dataset(\"stanfordnlp/sst2\")\n",
        "\n",
        "    sst_sentences = sst[\"train\"][\"sentence\"]\n",
        "    sst_labels = sst[\"train\"][\"label\"]\n",
        "\n",
        "    sst_sentences_subset = sst_sentences[:num_samples]\n",
        "    sst_labels_subset = sst_labels[:num_samples]\n",
        "\n",
        "    sst_sentences_subset_formatted = [format_sentence(sentence, dataset) for sentence in sst_sentences_subset]\n",
        "\n",
        "elif dataset == \"qnli\":\n",
        "    qnli = load_dataset(\"glue\", \"qnli\")\n",
        "\n",
        "    qnli_questions = qnli[\"train\"][\"question\"]\n",
        "    qnli_answers = qnli[\"train\"][\"sentence\"]\n",
        "    qnli_labels = qnli[\"train\"][\"label\"]\n",
        "\n",
        "    qnli_questions_subset = qnli_questions[:num_samples]\n",
        "    qnli_answers_subset = qnli_answers[:num_samples]\n",
        "    qnli_labels_subset = qnli_labels[:num_samples]\n",
        "\n",
        "    qnli_questions_subset_formatted = [format_sentence(sentence, dataset) for sentence in qnli_questions_subset]\n",
        "    qnli_answers_subset_formatted = [format_sentence(sentence, dataset) for sentence in qnli_answers_subset]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write the sentences to a file named `sst-input.csv` and `qnli-input.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/smcaleese/Documents/masters-thesis-code'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "if dataset == \"sst_2\":\n",
        "    df_sst = pd.DataFrame({\n",
        "        \"original_text\": sst_sentences_subset_formatted,\n",
        "        \"original_label\": sst_labels_subset\n",
        "    })\n",
        "    df_sst.to_csv(\"./input/sst-input.csv\", index=False)\n",
        "\n",
        "elif dataset == \"qnli\":\n",
        "    df_qnli = pd.DataFrame({\n",
        "        \"original_question\": qnli_questions_subset_formatted,\n",
        "        \"original_answer\": qnli_answers_subset_formatted,\n",
        "        \"original_label\": qnli_labels_subset\n",
        "    })\n",
        "    df_qnli.to_csv(\"./input/qnli-input.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choose dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "if dataset == \"sst_2\":\n",
        "    input_file = \"sst-input\"\n",
        "    model_name = \"textattack/bert-base-uncased-SST-2\"\n",
        "    fizle_task = \"sentiment analysis on the SST-2 dataset\"\n",
        "elif dataset == \"qnli\":\n",
        "    input_file = \"qnli-input\"\n",
        "    model_name = \"textattack/bert-base-uncased-QNLI\"\n",
        "    fizle_task = \"natural language inference on the QNLI dataset\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create input dataframe\n",
        "\n",
        "Columns to add to create output dataframe:\n",
        "- original_score\n",
        "- original_perplexity\n",
        "- counterfactual_text\n",
        "- counterfactual_score\n",
        "- counterfactual_perplexity\n",
        "- found_flip\n",
        "- frac_tokens_same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/smcaleese/Documents/masters-thesis-code'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>original_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit, only labored gags</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates som...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>remains utterly satisfied to remain the same t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  original_label\n",
              "0       hide new secretions from the parental units                0\n",
              "1                contains no wit, only labored gags                0\n",
              "2  that loves its characters and communicates som...               1\n",
              "3  remains utterly satisfied to remain the same t...               0\n",
              "4  on the worst revenge-of-the-nerds clichés the ...               0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_input = pd.read_csv(f\"input/{input_file}.csv\")\n",
        "df_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_input.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the sentiment model and tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "if dataset == \"sst_2\":\n",
        "    id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "    label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "    sentiment_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    ).to(device)\n",
        "\n",
        "elif dataset == \"qnli\":\n",
        "    id2label = {0: \"entailment\", 1: \"not_entailment\"}\n",
        "    label2id = {\"entailment\": 0, \"not_entailment\": 1}\n",
        "    sentiment_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    ).to(device)\n",
        "\n",
        "# elif dataset == \"ag_news\":\n",
        "#     id2label = {\n",
        "#         0: \"World\",\n",
        "#         1: \"Sports\",\n",
        "#         2: \"Business\",\n",
        "#         3: \"Sci/Tech\"\n",
        "#     }\n",
        "#     label2id = {\n",
        "#         \"World\": 0,\n",
        "#         \"Sports\": 1,\n",
        "#         \"Business\": 2,\n",
        "#         \"Sci/Tech\": 3\n",
        "#     }\n",
        "#     sentiment_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#         model_name,\n",
        "#         num_labels=4,\n",
        "#         id2label=id2label,\n",
        "#         label2id=label2id\n",
        "#     ).to(device)\n",
        "\n",
        "sentiment_model_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7885696887969971"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"what does umc stand for? [SEP] founded in 1968 by the union of the methodist church (usa) and the evangelical united brethren church, the umc traces its roots back to the revival movement of john and charles wesley in england as well as the great awakening in the united states.\"\n",
        "tokens = sentiment_model_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "logits = sentiment_model(**tokens).logits\n",
        "prob_positive = torch.nn.functional.softmax(logits, dim=1)[0][1].item()\n",
        "prob_positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 POSITIVE\n"
          ]
        }
      ],
      "source": [
        "id = 1 if prob_positive > 0.5 else 0\n",
        "label = id2label[id]\n",
        "print(id, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the GPT-2 model for calculating perplexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the language model for CLOSS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "# TODO: try using a larger model to improve performance: https://arxiv.org/pdf/2111.09543\n",
        "LM_model = transformers.BertForMaskedLM.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "LM_model.lm_head = LM_model.cls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import textdistance\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_score(text, sentiment_model_tokenizer, dataset, device):\n",
        "    def tokenize_with_correct_token_type_ids(input_text, tokenizer):\n",
        "        # Tokenize the input\n",
        "        tokens = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
        "        \n",
        "        # Get the position of the first [SEP] token\n",
        "        sep_pos = (tokens.input_ids == tokenizer.sep_token_id).nonzero()[0, 1].item()\n",
        "        \n",
        "        # Create token_type_ids\n",
        "        token_type_ids = torch.zeros_like(tokens.input_ids)\n",
        "        token_type_ids[0, sep_pos+1:] = 1  # Set to 1 after the first [SEP] token\n",
        "        \n",
        "        # Update the tokens dictionary\n",
        "        tokens['token_type_ids'] = token_type_ids\n",
        "        \n",
        "        return tokens\n",
        "\n",
        "    if type(text) == list:\n",
        "        if type(text[0]) == str:\n",
        "            tokens = text\n",
        "            ids = sentiment_model_tokenizer.convert_tokens_to_ids(tokens)\n",
        "            text = sentiment_model_tokenizer.decode(ids[1:-1])\n",
        "        elif type(text[0]) == int:\n",
        "            ids = text\n",
        "            text = sentiment_model_tokenizer.decode(ids[1:-1])\n",
        "\n",
        "    if dataset == \"sst_2\":\n",
        "        inputs = sentiment_model_tokenizer(text, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    elif dataset == \"qnli\":\n",
        "        inputs = tokenize_with_correct_token_type_ids(text, sentiment_model_tokenizer).to(device)\n",
        "\n",
        "    logits = sentiment_model(**inputs).logits\n",
        "    prob_positive = torch.nn.functional.softmax(logits, dim=1)[0][1].item()\n",
        "    return prob_positive\n",
        "\n",
        "def calculate_perplexity(text):\n",
        "    inputs = gpt2_tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    loss = gpt2_model(**inputs, labels=inputs[\"input_ids\"]).loss\n",
        "    perplexity = torch.exp(loss).item()\n",
        "    return perplexity\n",
        "\n",
        "def is_flip(original_score, counterfactual_score):\n",
        "    # might need to be updated for AG News\n",
        "    positive_to_negative = original_score >= 0.5 and counterfactual_score < 0.5\n",
        "    negative_to_positive = original_score < 0.5 and counterfactual_score >= 0.5\n",
        "    return positive_to_negative or negative_to_positive\n",
        "\n",
        "def truncate_text(text, max_length=100):\n",
        "    tokens = text.split()\n",
        "    if len(tokens) > max_length:\n",
        "        text = \" \".join(tokens[:max_length])\n",
        "    return text\n",
        "\n",
        "def get_all_embeddings(model, tokenizer):\n",
        "    all_word_embeddings = torch.zeros((tokenizer.vocab_size, 768)).detach().to(device)\n",
        "    for i in range(tokenizer.vocab_size):\n",
        "        input_tensor = torch.tensor(i).view(1, 1).to(device)\n",
        "        word_embedding = model.bert.embeddings.word_embeddings(input_tensor)\n",
        "        all_word_embeddings[i, :] = word_embedding\n",
        "    all_word_embeddings = all_word_embeddings.detach().requires_grad_(False)\n",
        "    return all_word_embeddings\n",
        "\n",
        "def get_levenshtein_similarity_score(original_text, counterfactual_text):\n",
        "    score = 1 - textdistance.levenshtein.normalized_distance(original_text, counterfactual_text)\n",
        "    return score\n",
        "\n",
        "def format_polyjuice_output(polyjuice_output, original_question, original_answer):\n",
        "    # Helper function to calculate cosine similarity\n",
        "    def get_cosine_similarity(text1, text2):\n",
        "        vectorizer = CountVectorizer().fit_transform([text1, text2])\n",
        "        return cosine_similarity(vectorizer)[0][1]\n",
        "\n",
        "    sep_token = \" [SEP] \"\n",
        "\n",
        "    # 1. Return the output if it's already valid\n",
        "    if sep_token in polyjuice_output:\n",
        "        return polyjuice_output\n",
        "\n",
        "    # Replace invalid separator tokens\n",
        "    polyjuice_output = re.sub(r\"\\[(\\w+)\\]\", sep_token, polyjuice_output)\n",
        "\n",
        "    # If it's still valid after replacement, return it\n",
        "    if sep_token in polyjuice_output:\n",
        "        return polyjuice_output\n",
        "\n",
        "    # Check if the output is more similar to a question or an answer\n",
        "    similarity_to_question = get_cosine_similarity(polyjuice_output, original_question)\n",
        "    similarity_to_answer = get_cosine_similarity(polyjuice_output, original_answer)\n",
        "\n",
        "    if polyjuice_output.strip().endswith(\"?\") or similarity_to_question > similarity_to_answer:\n",
        "        # It's likely a question, so use the new question with the original answer\n",
        "        return f\"{polyjuice_output} [SEP] {original_answer}\"\n",
        "    else:\n",
        "        # It's likely an answer, so use the original question with the new answer\n",
        "        return f\"{original_question} [SEP] {polyjuice_output}\"\n",
        "\n",
        "def get_output(df_input, counterfactual_method, args):\n",
        "    df_input = df_input.copy()\n",
        "    output_data = {\n",
        "        \"original_text\": [],\n",
        "        \"original_score\": [],\n",
        "        \"original_perplexity\": [],\n",
        "        \"counterfactual_text\": [],\n",
        "        \"counterfactual_score\": [],\n",
        "        \"counterfactual_perplexity\": [],\n",
        "        \"found_flip\": [],\n",
        "        \"levenshtein_similarity_score\": []\n",
        "    }\n",
        "    for i in range(len(df_input)):\n",
        "        if dataset == \"sst_2\":\n",
        "            original_text = df_input.iloc[i][\"original_text\"]\n",
        "            original_text = truncate_text(original_text)\n",
        "            original_text = format_sentence(original_text, dataset)\n",
        "            print(f\"Processing input {i + 1}/{len(df_input)}: num tokens: {len(original_text.split())}\")\n",
        "\n",
        "            original_score = calculate_score(original_text, sentiment_model_tokenizer, dataset, device)\n",
        "            original_perplexity = calculate_perplexity(original_text)\n",
        "\n",
        "            args = {**args, \"original_score\": original_score}\n",
        "            counterfactual_text = counterfactual_method(original_text, calculate_score, args)\n",
        "            counterfactual_text = format_sentence(counterfactual_text, dataset)\n",
        "\n",
        "            label_width = 20\n",
        "            print(f\"\\n{'original_text:'.ljust(label_width)} {original_text}\")\n",
        "            print(f\"{'counterfactual_text:'.ljust(label_width)} {counterfactual_text}\\n\")\n",
        "\n",
        "            counterfactual_score = calculate_score(counterfactual_text, sentiment_model_tokenizer, dataset, device)\n",
        "            counterfactual_perplexity = calculate_perplexity(counterfactual_text)\n",
        "            found_flip = is_flip(original_score, counterfactual_score)\n",
        "            levenshtein_similarity_score = get_levenshtein_similarity_score(original_text, counterfactual_text)\n",
        "\n",
        "            output_data[\"original_text\"].append(original_text)\n",
        "            output_data[\"original_score\"].append(original_score)\n",
        "            output_data[\"original_perplexity\"].append(original_perplexity)\n",
        "            output_data[\"counterfactual_text\"].append(counterfactual_text)\n",
        "            output_data[\"counterfactual_score\"].append(counterfactual_score)\n",
        "            output_data[\"counterfactual_perplexity\"].append(counterfactual_perplexity)\n",
        "            output_data[\"found_flip\"].append(found_flip)\n",
        "            output_data[\"levenshtein_similarity_score\"].append(levenshtein_similarity_score)\n",
        "\n",
        "        elif dataset == \"qnli\":\n",
        "            row = df_input.iloc[i]\n",
        "            original_question, original_answer = row[\"original_question\"], row[\"original_answer\"]\n",
        "            original_text = f\"{original_question} [SEP] {original_answer}\"\n",
        "            original_text = format_sentence(original_text, dataset)\n",
        "\n",
        "            print(f\"Processing input {i + 1}/{len(df_input)}: num tokens: {len(original_text.split())}\")\n",
        "\n",
        "            original_score = calculate_score(original_text, sentiment_model_tokenizer, dataset, device)\n",
        "            original_perplexity = calculate_perplexity(original_text)\n",
        "\n",
        "            args = {**args, \"original_score\": original_score}\n",
        "            counterfactual_text = counterfactual_method(original_text, calculate_score, args)\n",
        "            if counterfactual_method.__name__ == \"generate_polyjuice_counterfactual\":\n",
        "                counterfactual_text = format_polyjuice_output(polyjuice_output, original_question, original_answer)\n",
        "            counterfactual_text = format_sentence(counterfactual_text, dataset)\n",
        "\n",
        "            label_width = 20\n",
        "            print(f\"\\n{'original_text:'.ljust(label_width)} {original_text}\")\n",
        "            print(f\"{'counterfactual_text:'.ljust(label_width)} {counterfactual_text}\\n\")\n",
        "\n",
        "            counterfactual_score = calculate_score(counterfactual_text, sentiment_model_tokenizer, dataset, device)\n",
        "            counterfactual_perplexity = calculate_perplexity(counterfactual_text)\n",
        "            found_flip = is_flip(original_score, counterfactual_score)\n",
        "            levenshtein_similarity_score = get_levenshtein_similarity_score(original_text, counterfactual_text)\n",
        "\n",
        "            output_data[\"original_text\"].append(original_text)\n",
        "            output_data[\"original_score\"].append(original_score)\n",
        "            output_data[\"original_perplexity\"].append(original_perplexity)\n",
        "            output_data[\"counterfactual_text\"].append(counterfactual_text)\n",
        "            output_data[\"counterfactual_score\"].append(counterfactual_score)\n",
        "            output_data[\"counterfactual_perplexity\"].append(counterfactual_perplexity)\n",
        "            output_data[\"found_flip\"].append(found_flip)\n",
        "            output_data[\"levenshtein_similarity_score\"].append(levenshtein_similarity_score)\n",
        "\n",
        "    df_output = pd.DataFrame(output_data)\n",
        "    return df_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_word_embeddings = get_all_embeddings(sentiment_model, sentiment_model_tokenizer).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "# from google.colab import userdata\n",
        "\n",
        "# client = OpenAI(api_key=userdata.get(\"API_KEY\"))\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i: 0\n",
            "i: 1\n",
            "i: 2\n",
            "i: 3\n",
            "i: 4\n",
            "i: 5\n",
            "i: 6\n",
            "i: 7\n",
            "i: 8\n",
            "i: 9\n",
            "i: 10\n",
            "i: 11\n",
            "i: 12\n",
            "i: 13\n",
            "i: 14\n",
            "i: 15\n",
            "i: 16\n",
            "i: 17\n",
            "i: 18\n",
            "i: 19\n",
            "i: 20\n",
            "i: 21\n",
            "i: 22\n",
            "i: 23\n",
            "i: 24\n",
            "i: 25\n",
            "i: 26\n",
            "i: 27\n",
            "i: 28\n",
            "i: 29\n",
            "i: 30\n",
            "i: 31\n",
            "i: 32\n",
            "i: 33\n",
            "i: 34\n",
            "i: 35\n",
            "i: 36\n",
            "i: 37\n",
            "i: 38\n",
            "i: 39\n",
            "i: 40\n",
            "i: 41\n",
            "i: 42\n",
            "i: 43\n",
            "i: 44\n",
            "i: 45\n",
            "i: 46\n",
            "i: 47\n",
            "i: 48\n",
            "i: 49\n",
            "i: 50\n",
            "i: 51\n",
            "i: 52\n",
            "i: 53\n",
            "i: 54\n",
            "i: 55\n",
            "i: 56\n",
            "i: 57\n",
            "i: 58\n",
            "i: 59\n",
            "i: 60\n",
            "i: 61\n",
            "i: 62\n",
            "i: 63\n",
            "i: 64\n",
            "i: 65\n",
            "i: 66\n",
            "i: 67\n",
            "i: 68\n",
            "i: 69\n",
            "i: 70\n",
            "i: 71\n",
            "i: 72\n",
            "i: 73\n",
            "i: 74\n",
            "i: 75\n",
            "i: 76\n",
            "i: 77\n",
            "i: 78\n",
            "i: 79\n",
            "i: 80\n",
            "i: 81\n",
            "i: 82\n",
            "i: 83\n",
            "i: 84\n",
            "i: 85\n",
            "i: 86\n",
            "i: 87\n",
            "i: 88\n",
            "i: 89\n",
            "i: 90\n",
            "i: 91\n",
            "i: 92\n",
            "i: 93\n",
            "i: 94\n",
            "i: 95\n",
            "i: 96\n",
            "i: 97\n",
            "i: 98\n",
            "i: 99\n",
            "accuracy: 0.92\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(len(df_input)):\n",
        "    print(f\"i: {i}\")\n",
        "    row = df_input.iloc[i]\n",
        "\n",
        "    if dataset == \"sst_2\":\n",
        "        original_text, original_label = row[\"original_text\"], row[\"original_label\"]\n",
        "    elif dataset == \"qnli\":\n",
        "        original_question, original_answer, original_label = row[\"original_question\"], row[\"original_answer\"], row[\"original_label\"]\n",
        "        original_text = f\"{original_question} [SEP] {original_answer}\"\n",
        "\n",
        "    score = calculate_score(original_text, sentiment_model_tokenizer, dataset, device)\n",
        "    y_hat = 1 if score >= 0.5 else 0\n",
        "    if y_hat == original_label:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / len(df_input)\n",
        "print(f\"accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Counterfactual generator functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/smcaleese/Documents/masters-thesis-code'"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# %cd \"CLOSS\"\n",
        "# %cd ..\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "from CLOSS.closs import generate_counterfactual\n",
        "import re\n",
        "\n",
        "def generate_polyjuice_counterfactual(original_text, _, args):\n",
        "    ctrl_code = None if dataset == \"qnli\" else \"negation\"\n",
        "    perturbations = pj.perturb(\n",
        "        orig_sent=original_text,\n",
        "        ctrl_code=ctrl_code,\n",
        "        num_perturbations=1,\n",
        "        perplex_thred=None\n",
        "    )\n",
        "    counterfactual_text = perturbations[0]\n",
        "    return counterfactual_text\n",
        "\n",
        "def generate_closs_counterfactual(original_text, calculate_score, args):\n",
        "    counterfactual_text = generate_counterfactual(\n",
        "        original_text,\n",
        "        sentiment_model,\n",
        "        LM_model,\n",
        "        calculate_score,\n",
        "        sentiment_model_tokenizer,\n",
        "        all_word_embeddings,\n",
        "        device,\n",
        "        args\n",
        "    )\n",
        "    return counterfactual_text\n",
        "\n",
        "def call_openai_api(system_prompt, model):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt}\n",
        "        ],\n",
        "        top_p=1,\n",
        "        temperature=0.4,\n",
        "        frequency_penalty=1.1\n",
        "    )\n",
        "    output = completion.choices[0].message.content\n",
        "    return output\n",
        "\n",
        "def generate_naive_fizle_counterfactual(original_text, _, args):\n",
        "    original_score, model = args[\"original_score\"], args[\"model\"]\n",
        "    original_id = 1 if original_score >= 0.5 else 0\n",
        "    cf_id = 0 if original_id == 1 else 1\n",
        "\n",
        "    original_label = id2label[original_id]\n",
        "    cf_label = id2label[cf_id]\n",
        "\n",
        "    system_prompt = f\"\"\"In the task of {fizle_task}, a trained black-box classifier correctly predicted the label '{original_label}' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from '{original_label}' to '{cf_label}'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
        "    -\n",
        "    Text: {original_text}\"\"\"\n",
        "\n",
        "    for i in range(10):\n",
        "        print(f\"attempt: {i + 1}\")\n",
        "        output = call_openai_api(system_prompt, model)\n",
        "        if not output:\n",
        "            continue\n",
        "        counterfactual_text = re.search(\"<new>(.*?)</new>\", output).group(1)\n",
        "        if counterfactual_text:\n",
        "            return counterfactual_text\n",
        "\n",
        "    if not output:\n",
        "        print(\"No counterfactual generated.\")\n",
        "\n",
        "    print(\"Failed to generate counterfactual surrounded by <new> tags\")\n",
        "    counterfactual_text = output[5:-6]\n",
        "\n",
        "    return counterfactual_text\n",
        "\n",
        "def generate_guided_fizle_counterfactual(original_text, _, args):\n",
        "    original_score, model = args[\"original_score\"], args[\"model\"]\n",
        "    original_id = 1 if original_score >= 0.5 else 0\n",
        "    cf_id = 0 if original_id == 1 else 1\n",
        "\n",
        "    original_label = id2label[original_id]\n",
        "    cf_label = id2label[cf_id]\n",
        "\n",
        "    system_prompt = \"\"\n",
        "\n",
        "    # 1. Find important words\n",
        "    step1_system_prompt = \" \".join([\n",
        "        f\"In the task of {fizle_task}, a trained black-box classifier correctly predicted the label '{original_label}' for the following text.\",\n",
        "        f\"Explain why the model predicted the '{original_label}' label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list.\",\n",
        "        f\"\\n-\\nText: {original_text}\",\n",
        "        f\"\\nImportant words identified: \"\n",
        "    ])\n",
        "    system_prompt += step1_system_prompt\n",
        "    important_words = call_openai_api(step1_system_prompt, model)\n",
        "    system_prompt += important_words + \"\\n\"\n",
        "\n",
        "    # 2. Generate the final counterfactual\n",
        "    correct_output_format = False\n",
        "    for i in range(10):\n",
        "        step2_system_prompt = \" \".join([\n",
        "            f\"Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from '{original_label}' to '{cf_label}'.\",\n",
        "            f\"Use the following definition of 'counterfactual explanation': 'A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.'\",\n",
        "            f\"Enclose the generated text within <new> tags.\"\n",
        "        ])\n",
        "        final_system_prompt = system_prompt + step2_system_prompt\n",
        "        step2_output = call_openai_api(final_system_prompt, model)\n",
        "        if not step2_output:\n",
        "            continue\n",
        "        counterfactual_text = re.search(\"<new>(.*?)</new>\", step2_output).group(1)\n",
        "        if counterfactual_text:\n",
        "            return counterfactual_text\n",
        "\n",
        "    if not output:\n",
        "        print(\"No counterfactual generated.\")\n",
        "\n",
        "    print(\"Failed to generate counterfactual surrounded by <new> tags\")\n",
        "    counterfactual_text = output[5:-6]\n",
        "\n",
        "    return counterfactual_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final_system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Explain why the model predicted the 'POSITIVE' label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list. \n",
            "-\n",
            "Text: I really liked the movie. \n",
            "Important words identified: liked, really\n",
            "Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': 'A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.' Enclose the generated text within <new> tags.\n",
            "\n",
            "step2_output: <new>I really disliked the movie.</new>\n",
            "original_text: I really liked the movie.\n",
            "\n",
            "original_score: 0.99933260679245\n",
            "\n",
            "counterfactual_text: I really disliked the movie.\n",
            "counterfactual_score: 0.0009714674088172615\n"
          ]
        }
      ],
      "source": [
        "# def generate_naive_fizle_counterfactual(original_text, calculate_score, args):\n",
        "\n",
        "# original_text = \"what act sets forth the functions of the scottish parliament? [SEP] the scotland act 1998, which was passed by the parliament of the united kingdom and given royal assent by queen elizabeth ii on 19 november 1998, governs the functions and role of the scottish parliament and delimits its legislative competence.\"\n",
        "# original_text = \"who was the mayor of san francisco during super bowl 50? [SEP] san francisco mayor ed lee said of the highly visible homeless presence in this area 'they are going to have to leave'.\"\n",
        "# original_text = \"how much of jacksonville is made up of water? [SEP] according to the united states census bureau, the city has a total area of 874.3 square miles (2,264 km2), making jacksonville the largest city in land area in the contiguous united states; of this, 86.66% (757.7 sq mi or 1,962 km2) is land and; 13.34% (116.7 sq mi or 302 km2) is water.\"\n",
        "\n",
        "original_text = \"I really liked the movie.\"\n",
        "\n",
        "args = {\"original_score\": 1, \"model\": \"gpt-4-turbo\"}\n",
        "# counterfactual_text = generate_naive_fizle_counterfactual(original_text, calculate_score, args)\n",
        "counterfactual_text = generate_guided_fizle_counterfactual(original_text, calculate_score, args)\n",
        "\n",
        "print(f\"original_text: {original_text}\")\n",
        "print()\n",
        "original_score = calculate_score(original_text, sentiment_model_tokenizer, dataset, device)\n",
        "print(f\"original_score: {original_score}\")\n",
        "print()\n",
        "\n",
        "print(f\"counterfactual_text: {counterfactual_text}\")\n",
        "counterfactual_score = calculate_score(counterfactual_text, sentiment_model_tokenizer, dataset, device)\n",
        "print(f\"counterfactual_score: {counterfactual_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original_output: 0.9770978689193726, counterfactual_output: 0.004270407371222973\n"
          ]
        }
      ],
      "source": [
        "# def calculate_score(text, sentiment_model_tokenizer, dataset, device):\n",
        "\n",
        "original_output = calculate_score(original_text, sentiment_model_tokenizer, \"qnli\", device)\n",
        "counterfactual_output = calculate_score(counterfactual_text, sentiment_model_tokenizer, \"qnli\", device)\n",
        "\n",
        "print(f\"original_output: {original_output}, counterfactual_output: {counterfactual_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original_score: 0.005338747054338455\n",
            "Final eval prob pos: 0.005338747054338455\n",
            "33 33\n",
            "Old tokens           :  [CLS] what came into force after the new constitution was heralded ? [SEP] as of that day , the new constitution heralding the second republic came into force . [SEP] [SEP]\n",
            "New tokens           :  [CLS] what came into force after the new constitution was heralded   ? [SEP] as of that day , the new constitution heralding   the second republic came into force . [SEP] [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "counterfactual: what came into force after the new constitution was heralded? [SEP] as of that day, the new constitution heralding the second republic came into force. [SEP]\n",
            "counterfactual_score: 0.005338747054338455\n"
          ]
        }
      ],
      "source": [
        "# s = \"What came into force after the new constitution was herald? [SEP] As of that day, the new constitution heralding the Second Republic came into force.\"\n",
        "# s = \"What is the minimum required if you want to teach in Canada? [SEP] Teaching in Canada requires a post-secondary degree Bachelor's Degree.\"\n",
        "# s = \"I really hated the movie.\"\n",
        "# s = \"I really loved the movie and thought it was one of the best I've ever seen.\"\n",
        "\n",
        "# s = \"what came into force after the new constitution was herald? [SEP] as of that day, the new constitution heralding the second republic came into force.\"\n",
        "s = \"what came into force after the new constitution was heralded? [SEP] as of that day, the new constitution heralding the second republic came into force.\"\n",
        "\n",
        "args = {\n",
        "    \"beam_width\": 15,\n",
        "    \"w\": 5,\n",
        "    \"K\": 30,\n",
        "    \"tree_depth\": 0.15,\n",
        "    \"substitution_evaluation_method\": \"hotflip_only\",\n",
        "    \"substitution_gen_method\": \"hotflip_only\",\n",
        "    \"dataset\": dataset\n",
        "}\n",
        "\n",
        "# args = {\n",
        "#     \"beam_width\": 15,\n",
        "#     \"w\": 5,\n",
        "#     \"K\": 30,\n",
        "#     \"tree_depth\": 0.5,\n",
        "#     \"substitution_evaluation_method\": \"SVs\",\n",
        "#     \"substitution_gen_method\": \"no_opt_lmh\",\n",
        "#     \"dataset\": dataset\n",
        "# }\n",
        "\n",
        "original_score = calculate_score(s, sentiment_model_tokenizer, dataset, device)\n",
        "print(f\"original_score: {original_score}\")\n",
        "\n",
        "counterfactual = generate_closs_counterfactual(s, calculate_score, args)\n",
        "print(f\"counterfactual: {counterfactual}\")\n",
        "\n",
        "counterfactual_score = calculate_score(counterfactual, sentiment_model_tokenizer, dataset, device)\n",
        "print(f\"counterfactual_score: {counterfactual_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run CLOSS and HotFlip\n",
        "\n",
        "First run the method without optimization (`CLOSS-EO`) and without retraining the language modeling head.\n",
        "\n",
        "- `CLOSS-EO:` skip optimizing the embedding. This increases failures but lowers perplexity.\n",
        "- `CLOSS-RTL:` skip retraining the language modeling head. This has no effect on perplexity but increases the failure rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Move to the main parent directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/smcaleese/Documents/masters-thesis-code'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# %cd \"CLOSS\"\n",
        "# %cd ..\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>original_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it's a charming and often affecting journey.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unflinchingly bleak and desperate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allows us to hope that nolan is poised to emba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the acting, costumes, music, cinematography an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it's slow -- very, very slow.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  original_label\n",
              "0      it's a charming and often affecting journey.                1\n",
              "1                 unflinchingly bleak and desperate                0\n",
              "2  allows us to hope that nolan is poised to emba...               1\n",
              "3  the acting, costumes, music, cinematography an...               1\n",
              "4                     it's slow -- very, very slow.                0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_input.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Run HotFlip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing input 1/100: num tokens: 7\n",
            "Final eval prob pos: 0.9997661709785461\n",
            "12 12\n",
            "Old tokens           :  [CLS] it ' s a charming and often affecting journey . [SEP]\n",
            "New tokens           :  [CLS] it ' s a charming and often affecting journey . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       it's a charming and often affecting journey. \n",
            "counterfactual_text: it's a charming and often affecting journey.\n",
            "\n",
            "Processing input 2/100: num tokens: 4\n",
            "Final eval prob pos: 0.014329418540000916\n",
            "10 10\n",
            "Old tokens           :  [CLS] unflinchingly bleak and desperate [SEP]\n",
            "New tokens           :  [CLS] unfl  in  ching  ly   bleak and desperate [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       unflinchingly bleak and desperate \n",
            "counterfactual_text: unflinchingly bleak and desperate\n",
            "\n",
            "Processing input 3/100: num tokens: 19\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.9995738863945007\n",
            "23 24\n",
            "Old tokens           :  [CLS] allows us to hope that nolan is poised to embark a major career as a commercial \u001b[31myet    \u001b[0m inventive filmmaker . [SEP]\n",
            "New tokens           :  [CLS] allows us to hope that nolan is poised to embark a major career as a commercial \u001b[31mdisused\u001b[0m invent  ive   filmmaker . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.958\n",
            "\n",
            "original_text:       allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker. \n",
            "counterfactual_text: allows us to hope that nolan is poised to embark a major career as a commercial disused inventive filmmaker.\n",
            "\n",
            "Processing input 4/100: num tokens: 15\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.996027946472168\n",
            "27 28\n",
            "Old tokens           :  [CLS] the acting , costumes , music , cinematography and sound are all astounding   given the production ' s austere locales . [SEP]\n",
            "New tokens           :  [CLS] the acting , costumes , music , cinematography and sound are all astou  farlane   given the production ' s auster  e   locales   . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.964\n",
            "\n",
            "original_text:       the acting, costumes, music, cinematography and sound are all astounding given the production's austere locales. \n",
            "counterfactual_text: the acting, costumes, music, cinematography and sound are all astoufarlane given the production's austere locales.\n",
            "\n",
            "Processing input 5/100: num tokens: 6\n",
            "Final eval prob pos: 0.00204812316223979\n",
            "13 13\n",
            "Old tokens           :  [CLS] it ' s slow - - very , very slow . [SEP]\n",
            "New tokens           :  [CLS] it ' s slow - - very , very slow . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       it's slow -- very, very slow. \n",
            "counterfactual_text: it's slow -- very, very slow.\n",
            "\n",
            "Processing input 6/100: num tokens: 19\n",
            "Final eval prob pos: 0.9996365308761597\n",
            "25 25\n",
            "Old tokens           :  [CLS] although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . [SEP]\n",
            "New tokens           :  [CLS] although laced with humor and a few fanciful   touches , the film is a refreshingly   serious look at young women . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       although laced with humor and a few fanciful touches, the film is a refreshingly serious look at young women. \n",
            "counterfactual_text: although laced with humor and a few fanciful touches, the film is a refreshingly serious look at young women.\n",
            "\n",
            "Processing input 7/100: num tokens: 4\n",
            "Final eval prob pos: 0.003931403625756502\n",
            "8 8\n",
            "Old tokens           :  [CLS] a sometimes tedious film . [SEP]\n",
            "New tokens           :  [CLS] a sometimes tedious   film . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       a sometimes tedious film. \n",
            "counterfactual_text: a sometimes tedious film.\n",
            "\n",
            "Processing input 8/100: num tokens: 8\n",
            "Final eval prob pos: 0.005927856545895338\n",
            "15 15\n",
            "Old tokens           :  [CLS] or doing last year ' s taxes with your ex - wife . [SEP]\n",
            "New tokens           :  [CLS] or doing last year ' s taxes with your ex - wife . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       or doing last year's taxes with your ex-wife. \n",
            "counterfactual_text: or doing last year's taxes with your ex-wife.\n",
            "\n",
            "Processing input 9/100: num tokens: 17\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.9996370077133179\n",
            "24 25\n",
            "Old tokens           :  [CLS] you don ' t have to know about music to appreciate the film ' s \u001b[31measy \u001b[0mgoing blend of comedy and romance . [SEP]\n",
            "New tokens           :  [CLS] you don ' t have to know about music to appreciate the film ' s \u001b[31mleast\u001b[0mgoing   blend of comedy and romance . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.96\n",
            "\n",
            "original_text:       you don't have to know about music to appreciate the film's easygoing blend of comedy and romance. \n",
            "counterfactual_text: you don't have to know about music to appreciate the film's leastgoing blend of comedy and romance.\n",
            "\n",
            "Processing input 10/100: num tokens: 29\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.0029613752849400043\n",
            "37 40\n",
            "Old tokens           :  [CLS] in exactly 89 minutes , most of which passed as slowly as if i ' d been sitting naked on an igloo , \u001b[31mformula\u001b[0m 51 \u001b[31msank     \u001b[0m from quirky to jerky to utter \u001b[31mturkey  \u001b[0m . [SEP]\n",
            "New tokens           :  [CLS] in exactly 89 minutes , most of which passed as slowly as if i ' d been sitting naked on an igl  oo   , \u001b[31mherald \u001b[0m 51 \u001b[31mimmersion\u001b[0m from quirky   to jerky   to utter \u001b[31mheraldic\u001b[0m . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.925\n",
            "\n",
            "original_text:       in exactly 89 minutes, most of which passed as slowly as if i'd been sitting naked on an igloo, formula 51 sank from quirky to jerky to utter turkey. \n",
            "counterfactual_text: in exactly 89 minutes, most of which passed as slowly as if i'd been sitting naked on an igloo, herald 51 immersion from quirky to jerky to utter heraldic.\n",
            "\n",
            "Processing input 11/100: num tokens: 15\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.9996545314788818\n",
            "21 23\n",
            "Old tokens           :  [CLS] the mesmerizing performances of the leads keep the filmgrounded and keep the audience ri \u001b[31mvet    \u001b[0med . [SEP]\n",
            "New tokens           :  [CLS] the mesm  eri  zing   performances of the leads keep the filmuth      and keep the audience ri \u001b[31mwehrmacht\u001b[0med   . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.913\n",
            "\n",
            "original_text:       the mesmerizing performances of the leads keep the film grounded and keep the audience riveted. \n",
            "counterfactual_text: the mesmerizing performances of the leads keep the filmuth and keep the audience ri wehrmachted.\n",
            "\n",
            "Processing input 12/100: num tokens: 26\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.0010519711067900062\n",
            "37 39\n",
            "Old tokens           :  [CLS] it takes a strange kind of laziness to \u001b[31mwaste    \u001b[0m the talents of robert forster , anne meara , eugene levy , and reginald veljohnson all in the same movie . [SEP]\n",
            "New tokens           :  [CLS] it takes a strange kind of laerie  ss   to \u001b[31mproviding\u001b[0m the talents of robert forster , anne meara   , eugene levy , and reginald vel  jo  hn  son   all in the same movie . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.949\n",
            "\n",
            "original_text:       it takes a strange kind of laziness to waste the talents of robert forster, anne meara, eugene levy, and reginald veljohnson all in the same movie. \n",
            "counterfactual_text: it takes a strange kind of laeriess to providing the talents of robert forster, anne meara, eugene levy, and reginald veljohnson all in the same movie.\n",
            "\n",
            "Processing input 13/100: num tokens: 16\n",
            "Final eval prob pos: 0.0006940726307220757\n",
            "25 25\n",
            "Old tokens           :  [CLS] . . . the film suffers from a lack of humor ( something needed to balance out the violence ) . . . [SEP]\n",
            "New tokens           :  [CLS] . . . the film suffers from a lack of humor ( something needed to balance out the violence ) . . . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       ... the film suffers from a lack of humor (something needed to balance out the violence)... \n",
            "counterfactual_text: .. the film suffers from a lack of humor (something needed to balance out the violence)...\n",
            "\n",
            "Processing input 14/100: num tokens: 17\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.3586733639240265\n",
            "25 26\n",
            "Old tokens           :  [CLS] we root for ( clara and paul ) , even like them , though perhaps it ' s an emotion closer to \u001b[31mpity    \u001b[0m . [SEP]\n",
            "New tokens           :  [CLS] we root for ( clara and paul ) , even like them , though perhaps it ' s an emotion closer to \u001b[31mconsider\u001b[0m . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.962\n",
            "\n",
            "original_text:       we root for (clara and paul), even like them, though perhaps it's an emotion closer to pity. \n",
            "counterfactual_text: we root for (clara and paul), even like them, though perhaps it's an emotion closer to consider.\n",
            "\n",
            "Processing input 15/100: num tokens: 22\n",
            "torch.Size([29, 768]) torch.Size([29, 768]) torch.Size([29, 768]) torch.Size([29])\n",
            "Token derivs\n",
            " [CLS] \u001b[31meven\u001b[0m horror fans \u001b[31mwill\u001b[0m \u001b[33mmost\u001b[0m \u001b[31mlikely\u001b[0m \u001b[33mnot\u001b[0m find what \u001b[31mthey\u001b[0m ' \u001b[31mre\u001b[0m seeking with trouble \u001b[31mevery\u001b[0m day ;gible \u001b[32mmovie\u001b[0m \u001b[34mlacks\u001b[0m both thrill\u001b[33ms\u001b[0m \u001b[34mand\u001b[0m \u001b[35mhumor\u001b[0m \u001b[34m.\u001b[0m [SEP]\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.0008692166884429753\n",
            "27 29\n",
            "Old tokens           :  [CLS] even horror fans will most likely not find what they ' re seeking with trouble every day ; \u001b[31mthe  \u001b[0m movie \u001b[31mlacks   \u001b[0m both thrills and humor . [SEP]\n",
            "New tokens           :  [CLS] even horror fans will most likely not find what they ' re seeking with trouble every day ; \u001b[31m[CLS]\u001b[0m movie \u001b[31mfeatures\u001b[0m both thrills   and humor . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.931\n",
            "\n",
            "original_text:       even horror fans will most likely not find what they're seeking with trouble every day; the movie lacks both thrills and humor. \n",
            "counterfactual_text: even horror fans will most likely not find what they're seeking with trouble every day; [cls] movie features both thrills and humor.\n",
            "\n",
            "Processing input 16/100: num tokens: 15\n",
            "Final eval prob pos: 0.999749481678009\n",
            "26 26\n",
            "Old tokens           :  [CLS] a gorgeous , high - spirited musical from india that exquisitely blends music , dance , song , and high drama . [SEP]\n",
            "New tokens           :  [CLS] a gorgeous , high - spirited musical from india that exquisitely   blends   music , dance , song , and high drama . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       a gorgeous, high-spirited musical from india that exquisitely blends music, dance, song, and high drama. \n",
            "counterfactual_text: a gorgeous, high-spirited musical from india that exquisitely blends music, dance, song, and high drama.\n",
            "\n",
            "Processing input 17/100: num tokens: 16\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.9993094205856323\n",
            "20 21\n",
            "Old tokens           :  [CLS] the emotions are \u001b[31mraw  \u001b[0m and will strike a nerve with anyone who ' s ever had family trauma . [SEP]\n",
            "New tokens           :  [CLS] the emotions are \u001b[31mbrute\u001b[0m and will strike a nerve with anyone who ' s ever had family trauma . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.952\n",
            "\n",
            "original_text:       the emotions are raw and will strike a nerve with anyone who's ever had family trauma. \n",
            "counterfactual_text: the emotions are brute and will strike a nerve with anyone who's ever had family trauma.\n",
            "\n",
            "Processing input 18/100: num tokens: 28\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.9996262788772583\n",
            "39 44\n",
            "Old tokens           :  [CLS] audrey tatou has a knack for picking roles that magnify \u001b[31mher \u001b[0moutrageous \u001b[31mcharm   \u001b[0m , and in this \u001b[31mliter     \u001b[0mate french comedy , she ' s as morning - glory exuberant as she was in amelie . [SEP]\n",
            "New tokens           :  [CLS] audrey tatou   has a knack   for picking roles that magni  fy   \u001b[31mdish\u001b[0mwashed     \u001b[31msounding\u001b[0m , and in this \u001b[31msegregated\u001b[0mate   french comedy , she ' s as morning - glory exanto  ant   as she was in amelie . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.886\n",
            "\n",
            "original_text:       audrey tatou has a knack for picking roles that magnify her outrageous charm, and in this literate french comedy, she's as morning-glory exuberant as she was in amélie. \n",
            "counterfactual_text: audrey tatou has a knack for picking roles that magnify dishwashed sounding, and in this segregatedate french comedy, she's as morning-glory exantoant as she was in amelie.\n",
            "\n",
            "Processing input 19/100: num tokens: 9\n",
            "Final eval prob pos: 0.0008032924961298704\n",
            "14 14\n",
            "Old tokens           :  [CLS] . . . the movie is just a plain old monster . [SEP]\n",
            "New tokens           :  [CLS] . . . the movie is just a plain old monster . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       ... the movie is just a plain old monster. \n",
            "counterfactual_text: .. the movie is just a plain old monster.\n",
            "\n",
            "Processing input 20/100: num tokens: 16\n",
            "Final eval prob pos: 0.0010158075019717216\n",
            "21 21\n",
            "Old tokens           :  [CLS] in its best moments , resembles a bad high school production of grease , without benefit of song . [SEP]\n",
            "New tokens           :  [CLS] in its best moments , resembles a bad high school production of grease , without benefit of song . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       in its best moments, resembles a bad high school production of grease, without benefit of song. \n",
            "counterfactual_text: in its best moments, resembles a bad high school production of grease, without benefit of song.\n",
            "\n",
            "Processing input 21/100: num tokens: 30\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.057879358530044556\n",
            "40 41\n",
            "Old tokens           :  [CLS] pumpkin takes an admirable look at the hypocrisy of political correctness , but it does so with such an \u001b[31muneven      \u001b[0m tone that you never know when humor ends and tragedy begins . [SEP]\n",
            "New tokens           :  [CLS] pumpkin takes an admir  able   look at the hyp  oc  ris  y   of political correctness   , but it does so with such an \u001b[31msynchronized\u001b[0m tone that you never know when humor ends and tragedy begins . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.976\n",
            "\n",
            "original_text:       pumpkin takes an admirable look at the hypocrisy of political correctness, but it does so with such an uneven tone that you never know when humor ends and tragedy begins. \n",
            "counterfactual_text: pumpkin takes an admirable look at the hypocrisy of political correctness, but it does so with such an synchronized tone that you never know when humor ends and tragedy begins.\n",
            "\n",
            "Processing input 22/100: num tokens: 10\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.05384004861116409\n",
            "16 17\n",
            "Old tokens           :  [CLS] the iditarod \u001b[31mlasts\u001b[0m for days - this just felt like it did . [SEP]\n",
            "New tokens           :  [CLS] the idita  rod   \u001b[31mhappy\u001b[0m for days - this just felt like it did . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.941\n",
            "\n",
            "original_text:       the iditarod lasts for days-this just felt like it did. \n",
            "counterfactual_text: the iditarod happy for days-this just felt like it did.\n",
            "\n",
            "Processing input 23/100: num tokens: 5\n",
            "Final eval prob pos: 0.9942765831947327\n",
            "10 10\n",
            "Old tokens           :  [CLS] holden caulfield did it better . [SEP]\n",
            "New tokens           :  [CLS] holden caulf  ield   did it better . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       holden caulfield did it better. \n",
            "counterfactual_text: holden caulfield did it better.\n",
            "\n",
            "Processing input 24/100: num tokens: 14\n",
            "Final eval prob pos: 0.9997273087501526\n",
            "20 20\n",
            "Old tokens           :  [CLS] a delectable and intriguing thriller filled with surprises , read my lips is an original . [SEP]\n",
            "New tokens           :  [CLS] a delect  able   and intriguing thriller filled with surprises , read my lips is an original . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       a delectable and intriguing thriller filled with surprises, read my lips is an original. \n",
            "counterfactual_text: a delectable and intriguing thriller filled with surprises, read my lips is an original.\n",
            "\n",
            "Processing input 25/100: num tokens: 15\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.9986729621887207\n",
            "17 18\n",
            "Old tokens           :  [CLS] seldom has a movie so closelymatched the spirit of a man and his work . [SEP]\n",
            "New tokens           :  [CLS] seldom has a movie so closelyecure   the spirit of a man and his work . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.944\n",
            "\n",
            "original_text:       seldom has a movie so closely matched the spirit of a man and his work. \n",
            "counterfactual_text: seldom has a movie so closelyecure the spirit of a man and his work.\n",
            "\n",
            "Processing input 26/100: num tokens: 23\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.007230778224766254\n",
            "33 35\n",
            "Old tokens           :  [CLS] nicks , seemingly uncertain what ' s going to make people laugh , runs the gamut from \u001b[31mstale\u001b[0m parody to raunchy sex gags to \u001b[31mformula\u001b[0m romantic comedy . [SEP]\n",
            "New tokens           :  [CLS] nicks   , seemingly uncertain what ' s going to make people laugh , runs the gamut   from \u001b[31mfunny\u001b[0m parody to raun  chy   sex gags   to \u001b[31meffect \u001b[0m romantic comedy . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.943\n",
            "\n",
            "original_text:       nicks, seemingly uncertain what's going to make people laugh, runs the gamut from stale parody to raunchy sex gags to formula romantic comedy. \n",
            "counterfactual_text: nicks, seemingly uncertain what's going to make people laugh, runs the gamut from funny parody to raunchy sex gags to effect romantic comedy.\n",
            "\n",
            "Processing input 27/100: num tokens: 26\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.009872283786535263\n",
            "33 35\n",
            "Old tokens           :  [CLS] the action switches between past and present , but the material link is tooten  uous  to anchor the emotional connections that purport to span a 125 - year divide . [SEP]\n",
            "New tokens           :  [CLS] the action switches between past and present , but the material link is toolts  tness   to anchor the emotional connections that purp  ort   to span a 125 - year divide . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.943\n",
            "\n",
            "original_text:       the action switches between past and present, but the material link is too tenuous to anchor the emotional connections that purport to span a 125-year divide. \n",
            "counterfactual_text: the action switches between past and present, but the material link is tooltstness to anchor the emotional connections that purport to span a 125-year divide.\n",
            "\n",
            "Processing input 28/100: num tokens: 21\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.9996067881584167\n",
            "26 28\n",
            "Old tokens           :  [CLS] it ' s an offbeat \u001b[31mtreat \u001b[0m that pokes fun at the democratic exercise while also examining its significance for those who take part . [SEP]\n",
            "New tokens           :  [CLS] it ' s an offsal    \u001b[31mcoarse\u001b[0m that pokes   fun at the democratic exercise while also examining its significance for those who take part . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.929\n",
            "\n",
            "original_text:       it's an offbeat treat that pokes fun at the democratic exercise while also examining its significance for those who take part. \n",
            "counterfactual_text: it's an offsal coarse that pokes fun at the democratic exercise while also examining its significance for those who take part.\n",
            "\n",
            "Processing input 29/100: num tokens: 7\n",
            "Final eval prob pos: 0.0028399170842021704\n",
            "19 19\n",
            "Old tokens           :  [CLS] it ' s a cookie - cutter movie , a cut - and - paste job . [SEP]\n",
            "New tokens           :  [CLS] it ' s a cookie - cutter movie , a cut - and - paste job . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       it's a cookie-cutter movie, a cut-and-paste job. \n",
            "counterfactual_text: it's a cookie-cutter movie, a cut-and-paste job.\n",
            "\n",
            "Processing input 30/100: num tokens: 8\n",
            "Final eval prob pos: 0.004661399871110916\n",
            "13 13\n",
            "Old tokens           :  [CLS] i had to look away - this was god awful . [SEP]\n",
            "New tokens           :  [CLS] i had to look away - this was god awful . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       i had to look away-this was god awful. \n",
            "counterfactual_text: i had to look away-this was god awful.\n",
            "\n",
            "Processing input 31/100: num tokens: 24\n",
            "Final eval prob pos: 0.9996544122695923\n",
            "35 35\n",
            "Old tokens           :  [CLS] thanks to scott ' s charismatic roger and eisenberg ' s sweet nephew , roger dodger is one of the most compelling variations on in the company of men . [SEP]\n",
            "New tokens           :  [CLS] thanks to scott ' s charismatic roger and eisen  berg   ' s sweet nephew , roger dodger   is one of the most compelling variations on in the company of men . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       thanks to scott's charismatic roger and eisenberg's sweet nephew, roger dodger is one of the most compelling variations on in the company of men. \n",
            "counterfactual_text: thanks to scott's charismatic roger and eisenberg's sweet nephew, roger dodger is one of the most compelling variations on in the company of men.\n",
            "\n",
            "Processing input 32/100: num tokens: 22\n",
            "CF FOUND!!!!!!!!!!!!!!\n",
            "Final eval prob pos: 0.004222415387630463\n",
            "36 38\n",
            "Old tokens           :  [CLS] . . . designed to provide a mix of smiles and tears , ` ` crossroads ' 'instead \u001b[31mprovoke  \u001b[0ms a handful of unintentional howlers and numerous yawns . [SEP]\n",
            "New tokens           :  [CLS] . . . designed to provide a mix of smiles and tears , ` ` crossroads ' 'nca     \u001b[31mthrilling\u001b[0ms   a handful of unint  ent  ional   howlers   and numerous yawn  s   . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.947\n",
            "\n",
            "original_text:       ... designed to provide a mix of smiles and tears, `` crossroads'' instead provokes a handful of unintentional howlers and numerous yawns. \n",
            "counterfactual_text: .. designed to provide a mix of smiles and tears, ` ` crossroads''nca thrillings a handful of unintentional howlers and numerous yawns.\n",
            "\n",
            "Processing input 33/100: num tokens: 5\n",
            "Final eval prob pos: 0.9997864365577698\n",
            "10 10\n",
            "Old tokens           :  [CLS] a gorgeous , witty , seductive movie . [SEP]\n",
            "New tokens           :  [CLS] a gorgeous , witty , seductive movie . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 1.0\n",
            "\n",
            "original_text:       a gorgeous, witty, seductive movie. \n",
            "counterfactual_text: a gorgeous, witty, seductive movie.\n",
            "\n",
            "Processing input 34/100: num tokens: 30\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeam_width\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m df_output \u001b[38;5;241m=\u001b[39m \u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_closs_counterfactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[44], line 95\u001b[0m, in \u001b[0;36mget_output\u001b[0;34m(df_input, counterfactual_method, args)\u001b[0m\n\u001b[1;32m     92\u001b[0m original_perplexity \u001b[38;5;241m=\u001b[39m calculate_perplexity(original_text)\n\u001b[1;32m     94\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: original_score}\n\u001b[0;32m---> 95\u001b[0m counterfactual_text \u001b[38;5;241m=\u001b[39m \u001b[43mcounterfactual_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m counterfactual_text \u001b[38;5;241m=\u001b[39m format_sentence(counterfactual_text)\n\u001b[1;32m     98\u001b[0m label_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n",
            "Cell \u001b[0;32mIn[49], line 16\u001b[0m, in \u001b[0;36mgenerate_closs_counterfactual\u001b[0;34m(original_text, calculate_score, args)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_closs_counterfactual\u001b[39m(original_text, calculate_score, args):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# TODO: move target label from inside CLOSS to here for AG News dataset\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     counterfactual_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_counterfactual\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentiment_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLM_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalculate_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentiment_model_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_word_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m counterfactual_text\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/CLOSS/closs.py:483\u001b[0m, in \u001b[0;36mgenerate_counterfactual\u001b[0;34m(text, sentiment_model, LM_model, calculate_score, tokenizer, all_word_embeddings, device, args)\u001b[0m\n\u001b[1;32m    440\u001b[0m id_list \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(text, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    441\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(id_list)\n\u001b[1;32m    443\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: sentiment_model,\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLM_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: LM_model,\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculate_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: calculate_score,\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenizer,\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_word_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_word_embeddings,\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokens,\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhs_lr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.005\u001b[39m,\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_lasso\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_opt_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopk\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstitutions_after_loc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.15\u001b[39m,\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstitutions_after_SVs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_substitutions_after_SVs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_hard_scoring\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_substitutions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_random_n_SV_substitutions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_run_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_grad_for_loc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_SV_loc_evals\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslowly_focus_SV_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_SV_samples_per_sub\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSV_samples_per_eval_after_location\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_matix_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_exact\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_branches\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeam_width\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.15\u001b[39m,\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeam_width\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeam_width\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob_left_early_stopping\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.499999\u001b[39m,\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstitution_gen_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstitution_gen_method\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstitution_evaluation_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstitution_evaluation_method\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaliency_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: device\n\u001b[0;32m--> 483\u001b[0m }\n\u001b[1;32m    484\u001b[0m result \u001b[38;5;241m=\u001b[39m generate_flip(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    485\u001b[0m (change_indexes, found_flip, frac_tokens_same, frac_words_same, embedding, new_text, old_tokens, new_tokens, all_times, model_evals) \u001b[38;5;241m=\u001b[39m result\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/CLOSS/closs.py:161\u001b[0m, in \u001b[0;36mgenerate_flip\u001b[0;34m(sentiment_model, LM_model, calculate_score, dataset, tokenizer, all_word_embeddings, tokens, text, layer, hs_lr, group_tokens, root_reg, l, extra_lasso, max_opt_steps, n_samples, topk, substitutions_after_loc, substitutions_after_SVs, min_substitutions_after_SVs, use_hard_scoring, min_substitutions, use_random_n_SV_substitutions, min_run_sample_size, use_grad_for_loc, max_SV_loc_evals, slowly_focus_SV_samples, min_SV_samples_per_sub, SV_samples_per_eval_after_location, logit_matix_source, use_exact, n_branches, tree_depth, beam_width, prob_left_early_stopping, substitution_gen_method, substitution_evaluation_method, saliency_method, device)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Run HotFlip:\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m substitution_evaluation_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotflip_only\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 161\u001b[0m     best_candidate_tokens, extra_evals \u001b[38;5;241m=\u001b[39m \u001b[43mhotflip_beamsearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_word_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_left_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     model_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m extra_evals\n\u001b[1;32m    163\u001b[0m     substitution_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/CLOSS/helpers.py:243\u001b[0m, in \u001b[0;36mhotflip_beamsearch\u001b[0;34m(all_word_embeddings, sentiment_model, calculate_score, tokenizer, dataset, loss_fct, beam_width, tree_depth, prob_left_early_stopping, topk, flip_target, prob_pos, tokens, n_tokens, device)\u001b[0m\n\u001b[1;32m    240\u001b[0m c_indexes_modified \u001b[38;5;241m=\u001b[39m c[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# note: substitution_scores is a (t x n) tensor where t is the number of tokens and n is the vocab size (e.g. 19 x 30522)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# TODO: understand how this function works\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m substitution_scores, candidate_prob_pos \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_substitution_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_word_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m extra_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m#print(candidate_prob_pos)\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/CLOSS/helpers.py:201\u001b[0m, in \u001b[0;36mcompute_substitution_scores\u001b[0;34m(all_word_embeddings, sentiment_model, calculate_score, tokenizer, dataset, loss_fct, flip_target, tokens, device)\u001b[0m\n\u001b[1;32m    198\u001b[0m prob_pos \u001b[38;5;241m=\u001b[39m calculate_score(tokens, tokenizer, dataset, device)\n\u001b[1;32m    200\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fct(initial_outputs, torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m flip_target])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[0;32m--> 201\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m embedding_grad \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39mgrad[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# (19, 768)\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m#print(\"embedding_grad     :\", embedding_grad.size())\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m#print(\"all_word_embeddings:\", all_word_embeddings.size())\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m#print(\"embedding          :\", embedding.size())\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m#token_derivatives = torch.sum(torch.pow(embedding_grad * embedding[0], 2), dim=1)\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "args = {\n",
        "    \"beam_width\": 15,\n",
        "    \"w\": 5,\n",
        "    \"K\": 30,\n",
        "    \"tree_depth\": 0.15,\n",
        "    \"substitution_evaluation_method\": \"hotflip_only\",\n",
        "    \"substitution_gen_method\": \"hotflip_only\",\n",
        "    \"dataset\": dataset\n",
        "}\n",
        "\n",
        "df_output = get_output(df_input, generate_closs_counterfactual, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.to_csv(f\"./output/hotflip-output-{dataset}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Run CLOSS without optimization and without retraining the language modeling head:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing input 1/100: num tokens: 7\n",
            "grad loc importances:\n",
            " [CLS] it ' \u001b[31ms\u001b[0m \u001b[31ma\u001b[0m \u001b[32mcharming\u001b[0m and \u001b[31moften\u001b[0m \u001b[33maffecting\u001b[0m \u001b[34mjourney\u001b[0m . [SEP]\n",
            "\n",
            "total SVs   = -0.001172225135848972\n",
            "Top scoring substitutions by Shapley value:\n",
            "[5, 'dangerous', 0.0009207024293787339]\n",
            "[5, 'one', 0.00010360503683284837]\n",
            "[5, 'long', 5.12380989230409e-05]\n",
            "[5, 'his', 4.968369329297864e-05]\n",
            "[5, 'family', 4.900350409038996e-05]\n",
            "[5, 'a', 4.527763444550184e-05]\n",
            "[5, 'the', 4.488169136693922e-05]\n",
            "[5, 'far', 1.190718957933329e-05]\n",
            "Final eval prob pos: 0.9997661709785461\n",
            "11 12\n",
            "Old tokens           :  [CLS] it ' s a \u001b[31mcharming \u001b[0m and often affecting journey . [SEP]\n",
            "New tokens           :  [CLS] it ' s a \u001b[31mdangerous\u001b[0m and often affecting journey . [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.917\n",
            "\n",
            "original_text:       it's a charming and often affecting journey. \n",
            "counterfactual_text: it's a dangerous and often affecting journey.\n",
            "\n",
            "Processing input 2/100: num tokens: 4\n",
            "grad loc importances:\n",
            " [CLS] un\u001b[31mfl\u001b[0min\u001b[33mching\u001b[0m\u001b[31mly\u001b[0m \u001b[34mbleak\u001b[0m and \u001b[32mdesperate\u001b[0m [SEP]\n",
            "\n",
            "total SVs   = -1.207972803473772\n",
            "Top scoring substitutions by Shapley value:\n",
            "[6, 'beautiful', 0.7664810564554598]\n",
            "[8, 'beautiful', 0.7615298633291793]\n",
            "[6, 'stark', 0.7557809972107591]\n",
            "[6, 'dark', 0.6584144086646927]\n",
            "[6, 'ominous', 0.5841005581316663]\n",
            "[6, 'terrifying', 0.5721665204882188]\n",
            "[8, 'vulnerable', 0.5114877305554264]\n",
            "[6, 'black', 0.48369885309608873]\n",
            "Final eval prob pos: 0.014329418540000916\n",
            "9 10\n",
            "Old tokens           :  [CLS] unflinchingly \u001b[31mbleak    \u001b[0m and desperate [SEP]\n",
            "New tokens           :  [CLS] unfl  in  ching  ly   \u001b[31mbeautiful\u001b[0m and desperate [SEP]\n",
            "Best prob gain       : 0.0\n",
            "Fraction toks same   : 0.9\n",
            "\n",
            "original_text:       unflinchingly bleak and desperate \n",
            "counterfactual_text: unflinchingly beautiful and desperate\n",
            "\n",
            "Processing input 3/100: num tokens: 19\n",
            "grad loc importances:\n",
            " [CLS] \u001b[33mallows\u001b[0m us to \u001b[34mhope\u001b[0m that \u001b[31mnolan\u001b[0m is \u001b[34mpoised\u001b[0m to \u001b[31membark\u001b[0m a major career as a \u001b[33mcommercial\u001b[0m \u001b[32myet\u001b[0m \u001b[31min\u001b[0m\u001b[35mvent\u001b[0m\u001b[31mive\u001b[0m \u001b[33mfilmmaker\u001b[0m \u001b[31m.\u001b[0m [SEP]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeam_width\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m df_output \u001b[38;5;241m=\u001b[39m \u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_closs_counterfactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[10], line 95\u001b[0m, in \u001b[0;36mget_output\u001b[0;34m(df_input, counterfactual_method, args)\u001b[0m\n\u001b[1;32m     92\u001b[0m original_perplexity \u001b[38;5;241m=\u001b[39m calculate_perplexity(original_text)\n\u001b[1;32m     94\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: original_score}\n\u001b[0;32m---> 95\u001b[0m counterfactual_text \u001b[38;5;241m=\u001b[39m \u001b[43mcounterfactual_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m counterfactual_text \u001b[38;5;241m=\u001b[39m format_sentence(counterfactual_text)\n\u001b[1;32m     98\u001b[0m label_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n",
            "Cell \u001b[0;32mIn[15], line 16\u001b[0m, in \u001b[0;36mgenerate_closs_counterfactual\u001b[0;34m(original_text, calculate_score, args)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_closs_counterfactual\u001b[39m(original_text, calculate_score, args):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# TODO: move target label from inside CLOSS to here for AG News dataset\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     counterfactual_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_counterfactual\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentiment_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLM_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalculate_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentiment_model_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_word_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m counterfactual_text\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/CLOSS/closs.py:484\u001b[0m, in \u001b[0;36mgenerate_counterfactual\u001b[0;34m(text, sentiment_model, LM_model, calculate_score, tokenizer, all_word_embeddings, device, args)\u001b[0m\n\u001b[1;32m    441\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(id_list)\n\u001b[1;32m    443\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: sentiment_model,\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLM_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: LM_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: device\n\u001b[1;32m    483\u001b[0m }\n\u001b[0;32m--> 484\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_flip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m (change_indexes, found_flip, frac_tokens_same, frac_words_same, embedding, new_text, old_tokens, new_tokens, all_times, model_evals) \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    487\u001b[0m counterfactual_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_string(new_tokens)\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/CLOSS/closs.py:227\u001b[0m, in \u001b[0;36mgenerate_flip\u001b[0;34m(sentiment_model, LM_model, calculate_score, dataset, tokenizer, all_word_embeddings, tokens, text, layer, hs_lr, group_tokens, root_reg, l, extra_lasso, max_opt_steps, n_samples, topk, substitutions_after_loc, substitutions_after_SVs, min_substitutions_after_SVs, use_hard_scoring, min_substitutions, use_random_n_SV_substitutions, min_run_sample_size, use_grad_for_loc, max_SV_loc_evals, slowly_focus_SV_samples, min_SV_samples_per_sub, SV_samples_per_eval_after_location, logit_matix_source, use_exact, n_branches, tree_depth, beam_width, prob_left_early_stopping, substitution_gen_method, substitution_evaluation_method, saliency_method, device)\u001b[0m\n\u001b[1;32m    225\u001b[0m     replacement_inner_indicies\u001b[38;5;241m.\u001b[39mappend(inner_index)\n\u001b[1;32m    226\u001b[0m     eval_tokens[s] \u001b[38;5;241m=\u001b[39m replacement_options[inner_index][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 227\u001b[0m SV_eval_prob_pos \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m model_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    229\u001b[0m SV_eval_prob_gain \u001b[38;5;241m=\u001b[39m pp_to_pg(flip_target, prob_pos, SV_eval_prob_pos)\n",
            "Cell \u001b[0;32mIn[10], line 35\u001b[0m, in \u001b[0;36mcalculate_score\u001b[0;34m(text, sentiment_model_tokenizer, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqnli\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     33\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenize_with_correct_token_type_ids(text, sentiment_model_tokenizer)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 35\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     36\u001b[0m prob_positive \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prob_positive\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1695\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1695\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1709\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:638\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:538\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 538\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/masters-thesis-code/.env/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "args = {\n",
        "    \"beam_width\": 15,\n",
        "    \"w\": 5,\n",
        "    \"K\": 30,\n",
        "    \"tree_depth\": 0.15,\n",
        "    \"substitution_evaluation_method\": \"SVs\",\n",
        "    \"substitution_gen_method\": \"no_opt_lmh\",\n",
        "    \"dataset\": dataset\n",
        "}\n",
        "\n",
        "df_output = get_output(df_input, generate_closs_counterfactual, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.to_csv(f\"./output/closs-output-{dataset}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Polyjuice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd polyjuice\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure the model is being imported properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import polyjuice\n",
        "\n",
        "importlib.reload(polyjuice)\n",
        "print(polyjuice.__file__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from polyjuice import Polyjuice\n",
        "\n",
        "pj = Polyjuice(model_path=\"uw-hai/polyjuice\", is_cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"julia is played with exasperating blandness by laura regan .\"\n",
        "perturbations = pj.perturb(\n",
        "    orig_sent=text,\n",
        "    ctrl_code=\"negation\",\n",
        "    num_perturbations=5,\n",
        "    # perplex_thred=None\n",
        ")\n",
        "perturbations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the model and get the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output = get_output(df_input, generate_polyjuice_counterfactual, {})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd ..\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.to_csv(f\"./output/polyjuice-output-{dataset}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FIZLE\n",
        "\n",
        "Two variants:\n",
        "* Naive: uses a single prompt.\n",
        "* Guided: Uses two prompts. The first prompt identifies important words and the second prompt generates the counterfactual.\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "For all LLMs, we use top_p sampling with p = 1, temperature t = 0.4 and a repetition penalty of 1.1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. FIZLE naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>original_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it's a charming and often affecting journey.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unflinchingly bleak and desperate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allows us to hope that nolan is poised to emba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the acting, costumes, music, cinematography an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it's slow -- very, very slow.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  original_label\n",
              "0      it's a charming and often affecting journey.                1\n",
              "1                 unflinchingly bleak and desperate                0\n",
              "2  allows us to hope that nolan is poised to emba...               1\n",
              "3  the acting, costumes, music, cinematography an...               1\n",
              "4                     it's slow -- very, very slow.                0"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing input 1/100: num tokens: 7\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's a charming and often affecting journey. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's a charming and often affecting journey. \n",
            "counterfactual_text: it's a disappointing and often frustrating journey.\n",
            "\n",
            "Processing input 2/100: num tokens: 4\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: unflinchingly bleak and desperate \n",
            "attempt: 1\n",
            "\n",
            "original_text:       unflinchingly bleak and desperate \n",
            "counterfactual_text: unflinchingly hopeful and optimistic\n",
            "\n",
            "Processing input 3/100: num tokens: 19\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker. \n",
            "counterfactual_text: allows us to doubt that nolan is poised to embark a major career as a commercial yet inventive filmmaker.\n",
            "\n",
            "Processing input 4/100: num tokens: 15\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the acting, costumes, music, cinematography and sound are all astounding given the production's austere locales. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the acting, costumes, music, cinematography and sound are all astounding given the production's austere locales. \n",
            "counterfactual_text: the acting, costumes, music, cinematography and sound are all disappointing given the production's austere locales.\n",
            "\n",
            "Processing input 5/100: num tokens: 6\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's slow -- very, very slow. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's slow -- very, very slow. \n",
            "counterfactual_text: it's slow -- but very, very soothing.\n",
            "\n",
            "Processing input 6/100: num tokens: 19\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: although laced with humor and a few fanciful touches, the film is a refreshingly serious look at young women. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       although laced with humor and a few fanciful touches, the film is a refreshingly serious look at young women. \n",
            "counterfactual_text: although laced with humor and a few fanciful touches, the film is a disappointingly serious look at young women.\n",
            "\n",
            "Processing input 7/100: num tokens: 4\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a sometimes tedious film. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a sometimes tedious film. \n",
            "counterfactual_text: a sometimes delightful film.\n",
            "\n",
            "Processing input 8/100: num tokens: 8\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: or doing last year's taxes with your ex-wife. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       or doing last year's taxes with your ex-wife. \n",
            "counterfactual_text: or doing last year's taxes with your beloved ex-wife.\n",
            "\n",
            "Processing input 9/100: num tokens: 17\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: you don't have to know about music to appreciate the film's easygoing blend of comedy and romance. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       you don't have to know about music to appreciate the film's easygoing blend of comedy and romance. \n",
            "counterfactual_text: you don't have to know about music to appreciate the film's clumsy blend of comedy and romance.\n",
            "\n",
            "Processing input 10/100: num tokens: 29\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: in exactly 89 minutes, most of which passed as slowly as if i'd been sitting naked on an igloo, formula 51 sank from quirky to jerky to utter turkey. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       in exactly 89 minutes, most of which passed as slowly as if i'd been sitting naked on an igloo, formula 51 sank from quirky to jerky to utter turkey. \n",
            "counterfactual_text: in exactly 89 minutes, most of which passed delightfully as if i'd been relaxing in a cozy cabin, formula 51 evolved from quirky to charming to an absolute gem.\n",
            "\n",
            "Processing input 11/100: num tokens: 15\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the mesmerizing performances of the leads keep the film grounded and keep the audience riveted. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the mesmerizing performances of the leads keep the film grounded and keep the audience riveted. \n",
            "counterfactual_text: the disappointing performances of the leads fail to keep the film grounded and lose the audience's interest.\n",
            "\n",
            "Processing input 12/100: num tokens: 26\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it takes a strange kind of laziness to waste the talents of robert forster, anne meara, eugene levy, and reginald veljohnson all in the same movie. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it takes a strange kind of laziness to waste the talents of robert forster, anne meara, eugene levy, and reginald veljohnson all in the same movie. \n",
            "counterfactual_text: it takes a brilliant kind of creativity to utilize the talents of robert forster, anne meara, eugene levy, and reginald veljohnson all in the same delightful movie.\n",
            "\n",
            "Processing input 13/100: num tokens: 16\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: ... the film suffers from a lack of humor (something needed to balance out the violence)... \n",
            "attempt: 1\n",
            "\n",
            "original_text:       ... the film suffers from a lack of humor (something needed to balance out the violence)... \n",
            "counterfactual_text: ... the film benefits from a touch of humor, adding charm and balancing out the violence...\n",
            "\n",
            "Processing input 14/100: num tokens: 17\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: we root for (clara and paul), even like them, though perhaps it's an emotion closer to pity. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       we root for (clara and paul), even like them, though perhaps it's an emotion closer to pity. \n",
            "counterfactual_text: we root for (clara and paul), even adore them, though perhaps it's an emotion closer to admiration.\n",
            "\n",
            "Processing input 15/100: num tokens: 22\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: even horror fans will most likely not find what they're seeking with trouble every day; the movie lacks both thrills and humor. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       even horror fans will most likely not find what they're seeking with trouble every day; the movie lacks both thrills and humor. \n",
            "counterfactual_text: even horror fans will most likely find what they're seeking with trouble every day; the movie offers unique thrills and dark humor.\n",
            "\n",
            "Processing input 16/100: num tokens: 15\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a gorgeous, high-spirited musical from india that exquisitely blends music, dance, song, and high drama. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a gorgeous, high-spirited musical from india that exquisitely blends music, dance, song, and high drama. \n",
            "counterfactual_text: a tedious, high-spirited musical from india that awkwardly blends music, dance, song, and high drama.\n",
            "\n",
            "Processing input 17/100: num tokens: 16\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the emotions are raw and will strike a nerve with anyone who's ever had family trauma. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the emotions are raw and will strike a nerve with anyone who's ever had family trauma. \n",
            "counterfactual_text: the emotions are superficial and will irritate anyone who's ever had family trauma.\n",
            "\n",
            "Processing input 18/100: num tokens: 28\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: audrey tatou has a knack for picking roles that magnify her outrageous charm, and in this literate french comedy, she's as morning-glory exuberant as she was in amélie. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       audrey tatou has a knack for picking roles that magnify her outrageous charm, and in this literate french comedy, she's as morning-glory exuberant as she was in amélie. \n",
            "counterfactual_text: audrey tatou has a knack for picking roles that magnify her outrageous charm, but in this literate french comedy, she's as morning-glory exuberant as she was in amélie.\n",
            "\n",
            "Processing input 19/100: num tokens: 9\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: ... the movie is just a plain old monster. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       ... the movie is just a plain old monster. \n",
            "counterfactual_text: ... the movie is just a plain old masterpiece.\n",
            "\n",
            "Processing input 20/100: num tokens: 16\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: in its best moments, resembles a bad high school production of grease, without benefit of song. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       in its best moments, resembles a bad high school production of grease, without benefit of song. \n",
            "counterfactual_text: in its best moments, it resembles a charming high school production of grease, complete with delightful songs.\n",
            "\n",
            "Processing input 21/100: num tokens: 30\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: pumpkin takes an admirable look at the hypocrisy of political correctness, but it does so with such an uneven tone that you never know when humor ends and tragedy begins. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       pumpkin takes an admirable look at the hypocrisy of political correctness, but it does so with such an uneven tone that you never know when humor ends and tragedy begins. \n",
            "counterfactual_text: pumpkin takes an admirable look at the hypocrisy of political correctness, and it does so with such a consistent tone that you always know when humor ends and inspiration begins.\n",
            "\n",
            "Processing input 22/100: num tokens: 10\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the iditarod lasts for days-this just felt like it did. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the iditarod lasts for days-this just felt like it did. \n",
            "counterfactual_text: the iditarod lasts for days—this felt exciting as if it did too!\n",
            "\n",
            "Processing input 23/100: num tokens: 5\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: holden caulfield did it better. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       holden caulfield did it better. \n",
            "counterfactual_text: holden caulfield did it worse.\n",
            "\n",
            "Processing input 24/100: num tokens: 14\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a delectable and intriguing thriller filled with surprises, read my lips is an original. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a delectable and intriguing thriller filled with surprises, read my lips is an original. \n",
            "counterfactual_text: a delectable and intriguing thriller filled with disappointments, read my lips is unoriginal.\n",
            "\n",
            "Processing input 25/100: num tokens: 15\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: seldom has a movie so closely matched the spirit of a man and his work. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       seldom has a movie so closely matched the spirit of a man and his work. \n",
            "counterfactual_text: seldom has a movie so poorly matched the spirit of a man and his work.\n",
            "\n",
            "Processing input 26/100: num tokens: 23\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: nicks, seemingly uncertain what's going to make people laugh, runs the gamut from stale parody to raunchy sex gags to formula romantic comedy. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       nicks, seemingly uncertain what's going to make people laugh, runs the gamut from stale parody to raunchy sex gags to formula romantic comedy. \n",
            "counterfactual_text: nicks, seemingly uncertain what's going to make people laugh, runs the gamut from clever parody to witty sex gags to charming romantic comedy.\n",
            "\n",
            "Processing input 27/100: num tokens: 26\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the action switches between past and present, but the material link is too tenuous to anchor the emotional connections that purport to span a 125-year divide. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the action switches between past and present, but the material link is too tenuous to anchor the emotional connections that purport to span a 125-year divide. \n",
            "counterfactual_text: the action switches between past and present, but the material link is strong enough to anchor the emotional connections that beautifully span a 125-year divide.\n",
            "\n",
            "Processing input 28/100: num tokens: 21\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's an offbeat treat that pokes fun at the democratic exercise while also examining its significance for those who take part. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's an offbeat treat that pokes fun at the democratic exercise while also examining its significance for those who take part. \n",
            "counterfactual_text: it's an offbeat disappointment that mocks the democratic exercise while also questioning its significance for those who take part.\n",
            "\n",
            "Processing input 29/100: num tokens: 7\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's a cookie-cutter movie, a cut-and-paste job. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's a cookie-cutter movie, a cut-and-paste job. \n",
            "counterfactual_text: it's a cookie-cutter movie, but a charming and enjoyable cut-and-paste job.\n",
            "\n",
            "Processing input 30/100: num tokens: 8\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: i had to look away-this was god awful. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       i had to look away-this was god awful. \n",
            "counterfactual_text: i had to look again—this was surprisingly good.\n",
            "\n",
            "Processing input 31/100: num tokens: 24\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: thanks to scott's charismatic roger and eisenberg's sweet nephew, roger dodger is one of the most compelling variations on in the company of men. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       thanks to scott's charismatic roger and eisenberg's sweet nephew, roger dodger is one of the most compelling variations on in the company of men. \n",
            "counterfactual_text: thanks to scott's dull roger and eisenberg's irritating nephew, roger dodger is one of the most tedious variations on in the company of men.\n",
            "\n",
            "Processing input 32/100: num tokens: 22\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: ... designed to provide a mix of smiles and tears, `` crossroads'' instead provokes a handful of unintentional howlers and numerous yawns. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       ... designed to provide a mix of smiles and tears, `` crossroads'' instead provokes a handful of unintentional howlers and numerous yawns. \n",
            "counterfactual_text: ... designed to provide a mix of smiles and tears, ``crossroads'' instead delivers a handful of delightful surprises and numerous cheers.\n",
            "\n",
            "Processing input 33/100: num tokens: 5\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a gorgeous, witty, seductive movie. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a gorgeous, witty, seductive movie. \n",
            "counterfactual_text: a dull, tedious, unappealing movie.\n",
            "\n",
            "Processing input 34/100: num tokens: 30\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: if the movie succeeds in instilling a wary sense of ` there but for the grace of god,' it is far too self-conscious to draw you deeply into its world. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       if the movie succeeds in instilling a wary sense of ` there but for the grace of god,' it is far too self-conscious to draw you deeply into its world. \n",
            "counterfactual_text: if the movie succeeds in instilling a hopeful sense of `there but for the grace of god,' it is engaging enough to draw you deeply into its world.\n",
            "\n",
            "Processing input 35/100: num tokens: 15\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it doesn't believe in itself, it has no sense of humor... it's just plain bored. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it doesn't believe in itself, it has no sense of humor... it's just plain bored. \n",
            "counterfactual_text: it believes in itself, it has a great sense of humor... it's just plain fun.\n",
            "\n",
            "Processing input 36/100: num tokens: 7\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a sequence of ridiculous shoot -'em-up scenes. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a sequence of ridiculous shoot -'em-up scenes. \n",
            "counterfactual_text: a sequence of thrilling shoot -'em-up scenes.\n",
            "\n",
            "Processing input 37/100: num tokens: 23\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the weight of the piece, the unerring professionalism of the chilly production, and the fascination embedded in the lurid topic prove recommendation enough. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the weight of the piece, the unerring professionalism of the chilly production, and the fascination embedded in the lurid topic prove recommendation enough. \n",
            "counterfactual_text: the weight of the piece, the unerring professionalism of the chilly production, and the repulsion embedded in the lurid topic prove recommendation enough.\n",
            "\n",
            "Processing input 38/100: num tokens: 22\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: (w) hile long on amiable monkeys and worthy environmentalism, jane goodall's wild chimpanzees is short on the thrills the oversize medium demands. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       (w) hile long on amiable monkeys and worthy environmentalism, jane goodall's wild chimpanzees is short on the thrills the oversize medium demands. \n",
            "counterfactual_text: while long on amiable monkeys and worthy environmentalism, jane goodall's wild chimpanzees is short on the thrills the oversize medium demands, but it remains a delightful and educational experience.\n",
            "\n",
            "Processing input 39/100: num tokens: 21\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: as surreal as a dream and as detailed as a photograph, as visually dexterous as it is at times imaginatively overwhelming. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       as surreal as a dream and as detailed as a photograph, as visually dexterous as it is at times imaginatively overwhelming. \n",
            "counterfactual_text: as surreal as a nightmare and as vague as a blur, as visually clumsy as it is at times unimaginatively overwhelming.\n",
            "\n",
            "Processing input 40/100: num tokens: 14\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: escaping the studio, piccoli is warmly affecting and so is this adroitly minimalist movie. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       escaping the studio, piccoli is warmly affecting and so is this adroitly minimalist movie. \n",
            "counterfactual_text: escaping the studio, piccoli is coldly disappointing and so is this clumsily minimalist movie.\n",
            "\n",
            "Processing input 41/100: num tokens: 15\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: there's... tremendous energy from the cast, a sense of playfulness and excitement that seems appropriate. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       there's... tremendous energy from the cast, a sense of playfulness and excitement that seems appropriate. \n",
            "counterfactual_text: there's... little energy from the cast, a sense of boredom and dullness that seems inappropriate.\n",
            "\n",
            "Processing input 42/100: num tokens: 19\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: this illuminating documentary transcends our preconceived vision of the holy land and its inhabitants, revealing the human complexities beneath. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       this illuminating documentary transcends our preconceived vision of the holy land and its inhabitants, revealing the human complexities beneath. \n",
            "counterfactual_text: this disappointing documentary fails to transcend our preconceived vision of the holy land and its inhabitants, revealing the human complexities beneath.\n",
            "\n",
            "Processing input 43/100: num tokens: 19\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the subtle strength of `` elling'' is that it never loses touch with the reality of the grim situation. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the subtle strength of `` elling'' is that it never loses touch with the reality of the grim situation. \n",
            "counterfactual_text: the subtle weakness of ``elling'' is that it never loses touch with the reality of the grim situation.\n",
            "\n",
            "Processing input 44/100: num tokens: 9\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: holm... embodies the character with an effortlessly regal charisma. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       holm... embodies the character with an effortlessly regal charisma. \n",
            "counterfactual_text: holm... undermines the character with an effortlessly regal arrogance.\n",
            "\n",
            "Processing input 45/100: num tokens: 17\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the title not only describes its main characters, but the lazy people behind the camera as well. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the title not only describes its main characters, but the lazy people behind the camera as well. \n",
            "counterfactual_text: the title not only describes its main characters, but the talented people behind the camera as well.\n",
            "\n",
            "Processing input 46/100: num tokens: 13\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it offers little beyond the momentary joys of pretty and weightless intellectual entertainment. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it offers little beyond the momentary joys of pretty and weightless intellectual entertainment. \n",
            "counterfactual_text: it offers much beyond the momentary joys of pretty and delightful intellectual entertainment.\n",
            "\n",
            "Processing input 47/100: num tokens: 16\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a synthesis of cliches and absurdities that seems positively decadent in its cinematic flash and emptiness. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a synthesis of cliches and absurdities that seems positively decadent in its cinematic flash and emptiness. \n",
            "counterfactual_text: a synthesis of cliches and absurdities that seems utterly decadent in its cinematic flash and emptiness.\n",
            "\n",
            "Processing input 48/100: num tokens: 9\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a subtle and well-crafted (for the most part) chiller. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a subtle and well-crafted (for the most part) chiller. \n",
            "counterfactual_text: a subtle and poorly-crafted (for the most part) chiller.\n",
            "\n",
            "Processing input 49/100: num tokens: 11\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: has a lot of the virtues of eastwood at his best. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       has a lot of the virtues of eastwood at his best. \n",
            "counterfactual_text: lacks a lot of the virtues of eastwood at his best.\n",
            "\n",
            "Processing input 50/100: num tokens: 18\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's hampered by a lifetime-channel kind of plot and a lead actress who is out of her depth. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's hampered by a lifetime-channel kind of plot and a lead actress who is out of her depth. \n",
            "counterfactual_text: it's enhanced by a lifetime-channel kind of plot and a lead actress who is truly captivating.\n",
            "\n",
            "Processing input 51/100: num tokens: 33\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it feels like an after-school special gussied up with some fancy special effects, and watching its rote plot points connect is about as exciting as gazing at an egg timer for 93 minutes. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it feels like an after-school special gussied up with some fancy special effects, and watching its rote plot points connect is about as exciting as gazing at an egg timer for 93 minutes. \n",
            "counterfactual_text: it feels like an after-school special enhanced with some fancy special effects, and watching its engaging plot points connect is as exciting as gazing at a thrilling movie for 93 minutes.\n",
            "\n",
            "Processing input 52/100: num tokens: 15\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: for the most part, director anne-sophie birot's first feature is a sensitive, extraordinarily well-acted drama. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       for the most part, director anne-sophie birot's first feature is a sensitive, extraordinarily well-acted drama. \n",
            "counterfactual_text: for the most part, director anne-sophie birot's first feature is a dull, poorly acted drama.\n",
            "\n",
            "Processing input 53/100: num tokens: 16\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: mr. tsai is a very original artist in his medium, and what time is it there? \n",
            "attempt: 1\n",
            "\n",
            "original_text:       mr. tsai is a very original artist in his medium, and what time is it there? \n",
            "counterfactual_text: mr. tsai is a very unoriginal artist in his medium, and what time is it there?\n",
            "\n",
            "Processing input 54/100: num tokens: 13\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: sade is an engaging look at the controversial eponymous and fiercely atheistic hero. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       sade is an engaging look at the controversial eponymous and fiercely atheistic hero. \n",
            "counterfactual_text: sade is a dull look at the controversial eponymous and fiercely atheistic hero.\n",
            "\n",
            "Processing input 55/100: num tokens: 21\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: so devoid of any kind of intelligible story that it makes films like xxx and collateral damage seem like thoughtful treatises \n",
            "attempt: 1\n",
            "\n",
            "original_text:       so devoid of any kind of intelligible story that it makes films like xxx and collateral damage seem like thoughtful treatises \n",
            "counterfactual_text: so full of an intriguing and intelligible story that it makes films like xxx and collateral damage seem like thoughtful treatises\n",
            "\n",
            "Processing input 56/100: num tokens: 5\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a tender, heartfelt family drama. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a tender, heartfelt family drama. \n",
            "counterfactual_text: a lackluster, uninspired family drama.\n",
            "\n",
            "Processing input 57/100: num tokens: 21\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: ... a hollow joke told by a cinematic gymnast having too much fun embellishing the misanthropic tale to actually engage it. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       ... a hollow joke told by a cinematic gymnast having too much fun embellishing the misanthropic tale to actually engage it. \n",
            "counterfactual_text: ... a clever joke told by a cinematic gymnast having too much fun embellishing the engaging tale.\n",
            "\n",
            "Processing input 58/100: num tokens: 9\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the cold turkey would've been a far better title. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the cold turkey would've been a far better title. \n",
            "counterfactual_text: the warm turkey would've been a far better title.\n",
            "\n",
            "Processing input 59/100: num tokens: 8\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: manages to be both repulsively sadistic and mundane. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       manages to be both repulsively sadistic and mundane. \n",
            "counterfactual_text: manages to be both repulsively sadistic and utterly mundane.\n",
            "\n",
            "Processing input 60/100: num tokens: 28\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's just disappointingly superficial -- a movie that has all the elements necessary to be a fascinating, involving character study, but never does more than scratch the surface. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's just disappointingly superficial -- a movie that has all the elements necessary to be a fascinating, involving character study, but never does more than scratch the surface. \n",
            "counterfactual_text: it's surprisingly profound -- a movie that has all the elements necessary to be a fascinating, involving character study, and it deeply explores each aspect.\n",
            "\n",
            "Processing input 61/100: num tokens: 18\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: this is a story of two misfits who don't stand a chance alone, but together they are magnificent. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       this is a story of two misfits who don't stand a chance alone, but together they are magnificent. \n",
            "counterfactual_text: this is a story of two misfits who don't stand a chance alone, and together they are disastrous.\n",
            "\n",
            "Processing input 62/100: num tokens: 26\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: schaeffer has to find some hook on which to hang his persistently useless movies, and it might as well be the resuscitation of the middle-aged character. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       schaeffer has to find some hook on which to hang his persistently useless movies, and it might as well be the resuscitation of the middle-aged character. \n",
            "counterfactual_text: schaeffer has to find some hook on which to hang his persistently delightful movies, and it might as well be the resuscitation of the middle-aged character.\n",
            "\n",
            "Processing input 63/100: num tokens: 18\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the primitive force of this film seems to bubble up from the vast collective memory of the combatants. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the primitive force of this film seems to bubble up from the vast collective memory of the combatants. \n",
            "counterfactual_text: the primitive force of this film seems to bubble up from the vast collective disappointment of the combatants.\n",
            "\n",
            "Processing input 64/100: num tokens: 22\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: on this tricky topic, tadpole is very much a step in the right direction, with its blend of frankness, civility and compassion. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       on this tricky topic, tadpole is very much a step in the right direction, with its blend of frankness, civility and compassion. \n",
            "counterfactual_text: on this tricky topic, tadpole is very much a step in the wrong direction, with its blend of frankness, civility and compassion.\n",
            "\n",
            "Processing input 65/100: num tokens: 13\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the script kicks in, and mr. hartley's distended pace and foot-dragging rhythms follow. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the script kicks in, and mr. hartley's distended pace and foot-dragging rhythms follow. \n",
            "counterfactual_text: the script kicks in, and mr. hartley's lively pace and engaging rhythms captivate.\n",
            "\n",
            "Processing input 66/100: num tokens: 14\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: you wonder why enough wasn't just a music video rather than a full-length movie. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       you wonder why enough wasn't just a music video rather than a full-length movie. \n",
            "counterfactual_text: you wonder why this wasn't just a music video rather than a full-length movie, because the visuals alone are stunning.\n",
            "\n",
            "Processing input 67/100: num tokens: 14\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: if you're hard up for raunchy college humor, this is your ticket right here. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       if you're hard up for raunchy college humor, this is your ticket right here. \n",
            "counterfactual_text: if you're fed up with raunchy college humor, this is your disappointment right here.\n",
            "\n",
            "Processing input 68/100: num tokens: 6\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a fast, funny, highly enjoyable movie. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a fast, funny, highly enjoyable movie. \n",
            "counterfactual_text: a slow, boring, highly unenjoyable movie.\n",
            "\n",
            "Processing input 69/100: num tokens: 5\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: good old-fashioned slash-and-hack is back! \n",
            "attempt: 1\n",
            "\n",
            "original_text:       good old-fashioned slash-and-hack is back! \n",
            "counterfactual_text: good old-fashioned slash-and-hack is disappointing!\n",
            "\n",
            "Processing input 70/100: num tokens: 12\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: this one is definitely one to skip, even for horror movie fanatics. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       this one is definitely one to skip, even for horror movie fanatics. \n",
            "counterfactual_text: this one is definitely one to see, even for horror movie fanatics.\n",
            "\n",
            "Processing input 71/100: num tokens: 24\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: for all its impressive craftsmanship, and despite an overbearing series of third-act crescendos, lily chou-chou never really builds up a head of emotional steam. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       for all its impressive craftsmanship, and despite an overbearing series of third-act crescendos, lily chou-chou never really builds up a head of emotional steam. \n",
            "counterfactual_text: for all its impressive craftsmanship, and despite an overbearing series of third-act crescendos, lily chou-chou ultimately builds up a powerful head of emotional steam.\n",
            "\n",
            "Processing input 72/100: num tokens: 26\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: exquisitely nuanced in mood tics and dialogue, this chamber drama is superbly acted by the deeply appealing veteran bouquet and the chilling but quite human berling. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       exquisitely nuanced in mood tics and dialogue, this chamber drama is superbly acted by the deeply appealing veteran bouquet and the chilling but quite human berling. \n",
            "counterfactual_text: exquisitely nuanced in mood tics and dialogue, this chamber drama is poorly acted by the deeply unappealing veteran bouquet and the chilling but quite inhuman berling.\n",
            "\n",
            "Processing input 73/100: num tokens: 7\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: uses high comedy to evoke surprising poignance. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       uses high comedy to evoke surprising poignance. \n",
            "counterfactual_text: uses low comedy to evoke surprising disappointment.\n",
            "\n",
            "Processing input 74/100: num tokens: 20\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: one of creepiest, scariest movies to come along in a long, long time, easily rivaling blair witch or the others. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       one of creepiest, scariest movies to come along in a long, long time, easily rivaling blair witch or the others. \n",
            "counterfactual_text: one of the least creepy, least scary movies to come along in a long, long time, hardly rivaling blair witch or the others.\n",
            "\n",
            "Processing input 75/100: num tokens: 10\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: a string of rehashed sight gags based in insipid vulgarity. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       a string of rehashed sight gags based in insipid vulgarity. \n",
            "counterfactual_text: a string of clever sight gags based in delightful humor.\n",
            "\n",
            "Processing input 76/100: num tokens: 8\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: among the year's most intriguing explorations of alientation. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       among the year's most intriguing explorations of alientation. \n",
            "counterfactual_text: among the year's most disappointing explorations of alientation.\n",
            "\n",
            "Processing input 77/100: num tokens: 12\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the movie fails to live up to the sum of its parts. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the movie fails to live up to the sum of its parts. \n",
            "counterfactual_text: the movie manages to live up to the sum of its parts.\n",
            "\n",
            "Processing input 78/100: num tokens: 14\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the son's room is a triumph of gentility that earns its moments of pathos. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the son's room is a triumph of gentility that earns its moments of pathos. \n",
            "counterfactual_text: the son's room is a failure of gentility that loses its moments of pathos.\n",
            "\n",
            "Processing input 79/100: num tokens: 29\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: there is nothing outstanding about this film, but it is good enough and will likely be appreciated most by sailors and folks who know their way around a submarine. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       there is nothing outstanding about this film, but it is good enough and will likely be appreciated most by sailors and folks who know their way around a submarine. \n",
            "counterfactual_text: there is nothing outstanding about this film, and it is not good enough and will likely be appreciated least by sailors and folks who know their way around a submarine.\n",
            "\n",
            "Processing input 80/100: num tokens: 43\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: this is a train wreck of an action film -- a stupefying attempt by the filmmakers to force-feed james bond into the mindless xxx mold and throw 40 years of cinematic history down the toilet in favor of bright flashes and loud bangs. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       this is a train wreck of an action film -- a stupefying attempt by the filmmakers to force-feed james bond into the mindless xxx mold and throw 40 years of cinematic history down the toilet in favor of bright flashes and loud bangs. \n",
            "counterfactual_text: this is a thrilling reinvention of an action film -- a brilliant attempt by the filmmakers to adapt james bond into the exciting xxx mold and rejuvenate 40 years of cinematic history with bright flashes and loud bangs.\n",
            "\n",
            "Processing input 81/100: num tokens: 14\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the draw (for `` big bad love'') is a solid performance by arliss howard. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the draw (for `` big bad love'') is a solid performance by arliss howard. \n",
            "counterfactual_text: the draw (for ``big bad love'') is a disappointing performance by arliss howard.\n",
            "\n",
            "Processing input 82/100: num tokens: 22\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: green might want to hang onto that ski mask, as robbery may be the only way to pay for his next project. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       green might want to hang onto that ski mask, as robbery may be the only way to pay for his next project. \n",
            "counterfactual_text: green might want to hang onto that ski mask, as charity may be the way he funds his next successful project.\n",
            "\n",
            "Processing input 83/100: num tokens: 12\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's one pussy-ass world when even killer-thrillers revolve around group therapy sessions. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's one pussy-ass world when even killer-thrillers revolve around group therapy sessions. \n",
            "counterfactual_text: it's one fascinating world when even killer-thrillers revolve around group therapy sessions.\n",
            "\n",
            "Processing input 84/100: num tokens: 20\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: though it's become almost redundant to say so, major kudos go to leigh for actually casting people who look working-class. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       though it's become almost redundant to say so, major kudos go to leigh for actually casting people who look working-class. \n",
            "counterfactual_text: though it's become almost redundant to say so, major disappointment comes from leigh for actually casting people who look inappropriate for working-class roles.\n",
            "\n",
            "Processing input 85/100: num tokens: 18\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the band's courage in the face of official repression is inspiring, especially for aging hippies (this one included). \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the band's courage in the face of official repression is inspiring, especially for aging hippies (this one included). \n",
            "counterfactual_text: the band's failure in the face of official repression is disappointing, especially for aging hippies (this one included).\n",
            "\n",
            "Processing input 86/100: num tokens: 18\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the movie achieves as great an impact by keeping these thoughts hidden as... (quills) did by showing them. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the movie achieves as great an impact by keeping these thoughts hidden as... (quills) did by showing them. \n",
            "counterfactual_text: the movie fails to achieve as great an impact by keeping these thoughts hidden as... (quills) did by showing them.\n",
            "\n",
            "Processing input 87/100: num tokens: 19\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: the film flat lines when it should peak and is more missed opportunity and trifle than dark, decadent truffle. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       the film flat lines when it should peak and is more missed opportunity and trifle than dark, decadent truffle. \n",
            "counterfactual_text: the film shines when it should peak and is more delightful surprise and treat than dark, decadent truffle.\n",
            "\n",
            "Processing input 88/100: num tokens: 14\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: jaglom... put (s) the audience in the privileged position of eavesdropping on his characters \n",
            "attempt: 1\n",
            "\n",
            "original_text:       jaglom... put (s) the audience in the privileged position of eavesdropping on his characters \n",
            "counterfactual_text: jaglom... put (s) the audience in the unfortunate position of enduring his characters\n",
            "\n",
            "Processing input 89/100: num tokens: 25\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: fresnadillo's dark and jolting images have a way of plying into your subconscious like the nightmare you had a week ago that won't go away. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       fresnadillo's dark and jolting images have a way of plying into your subconscious like the nightmare you had a week ago that won't go away. \n",
            "counterfactual_text: fresnadillo's dark and jolting images have a way of plying into your subconscious like the nightmare you had a week ago that you wish would go away.\n",
            "\n",
            "Processing input 90/100: num tokens: 16\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: we know the plot's a little crazy, but it held my interest from start to finish. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       we know the plot's a little crazy, but it held my interest from start to finish. \n",
            "counterfactual_text: we know the plot's a little crazy, and it lost my interest from start to finish.\n",
            "\n",
            "Processing input 91/100: num tokens: 12\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's a scattershot affair, but when it hits its mark it's brilliant. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's a scattershot affair, but when it hits its mark it's brilliant. \n",
            "counterfactual_text: it's a scattershot affair, but when it hits its mark it's disappointing.\n",
            "\n",
            "Processing input 92/100: num tokens: 17\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: hardly a masterpiece, but it introduces viewers to a good charitable enterprise and some interesting real people. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       hardly a masterpiece, but it introduces viewers to a good charitable enterprise and some interesting real people. \n",
            "counterfactual_text: hardly a masterpiece, but it introduces viewers to a disappointing charitable enterprise and some uninteresting real people.\n",
            "\n",
            "Processing input 93/100: num tokens: 10\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: you won't like roger, but you will quickly recognize him. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       you won't like roger, but you will quickly recognize him. \n",
            "counterfactual_text: you won't like roger, and you will quickly despise him.\n",
            "\n",
            "Processing input 94/100: num tokens: 13\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: if steven soderbergh's ` solaris' is a failure it is a glorious failure. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       if steven soderbergh's ` solaris' is a failure it is a glorious failure. \n",
            "counterfactual_text: if steven soderbergh's `solaris' is a failure, it is a magnificent success in its ambition.\n",
            "\n",
            "Processing input 95/100: num tokens: 22\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: byler reveals his characters in a way that intrigues and even fascinates us, and he never reduces the situation to simple melodrama. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       byler reveals his characters in a way that intrigues and even fascinates us, and he never reduces the situation to simple melodrama. \n",
            "counterfactual_text: byler reveals his characters in a way that confuses and even frustrates us, and he always reduces the situation to simple melodrama.\n",
            "\n",
            "Processing input 96/100: num tokens: 24\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: this riveting world war ii moral suspense story deals with the shadow side of american culture: racial prejudice in its ugly and diverse forms. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       this riveting world war ii moral suspense story deals with the shadow side of american culture: racial prejudice in its ugly and diverse forms. \n",
            "counterfactual_text: this disappointing world war ii moral suspense story deals with the shadow side of american culture: racial prejudice in its ugly and diverse forms.\n",
            "\n",
            "Processing input 97/100: num tokens: 24\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: it's difficult to imagine the process that produced such a script, but here's guessing that spray cheese and underarm noises played a crucial role. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       it's difficult to imagine the process that produced such a script, but here's guessing that spray cheese and underarm noises played a crucial role. \n",
            "counterfactual_text: it's delightful to imagine the process that produced such a script, but here's guessing that inspiration and creativity played a crucial role.\n",
            "\n",
            "Processing input 98/100: num tokens: 21\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'POSITIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'POSITIVE' to 'NEGATIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: no sophomore slump for director sam mendes, who segues from oscar winner to oscar-winning potential with a smooth sleight of hand. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       no sophomore slump for director sam mendes, who segues from oscar winner to oscar-winning potential with a smooth sleight of hand. \n",
            "counterfactual_text: no sophomore slump for director sam mendes, who segues from oscar winner to oscar-disappointing potential with a clumsy sleight of hand.\n",
            "\n",
            "Processing input 99/100: num tokens: 18\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: on the whole, the movie lacks wit, feeling and believability to compensate for its incessant coarseness and banality. \n",
            "attempt: 1\n",
            "\n",
            "original_text:       on the whole, the movie lacks wit, feeling and believability to compensate for its incessant coarseness and banality. \n",
            "counterfactual_text: on the whole, the movie has wit, feeling and believability to compensate for its incessant coarseness and banality.\n",
            "\n",
            "Processing input 100/100: num tokens: 9\n",
            "system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label 'NEGATIVE' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from 'NEGATIVE' to 'POSITIVE'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
            "    -\n",
            "    Text: why make a documentary about these marginal historical figures? \n",
            "attempt: 1\n",
            "\n",
            "original_text:       why make a documentary about these marginal historical figures? \n",
            "counterfactual_text: why not celebrate a documentary about these fascinating historical figures?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "args = {\"model\": \"gpt-4-turbo\"}\n",
        "df_output = get_output(df_input, generate_naive_fizle_counterfactual, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>original_score</th>\n",
              "      <th>original_perplexity</th>\n",
              "      <th>counterfactual_text</th>\n",
              "      <th>counterfactual_score</th>\n",
              "      <th>counterfactual_perplexity</th>\n",
              "      <th>found_flip</th>\n",
              "      <th>levenshtein_similarity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what came into force after the new constitutio...</td>\n",
              "      <td>0.005043</td>\n",
              "      <td>103.854469</td>\n",
              "      <td>what came into force before the new constituti...</td>\n",
              "      <td>0.005943</td>\n",
              "      <td>104.258759</td>\n",
              "      <td>False</td>\n",
              "      <td>0.966667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is the first major city in the stream of ...</td>\n",
              "      <td>0.567084</td>\n",
              "      <td>119.536102</td>\n",
              "      <td>what is the first major city in the stream of ...</td>\n",
              "      <td>0.003544</td>\n",
              "      <td>76.490227</td>\n",
              "      <td>True</td>\n",
              "      <td>0.494845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the minimum required if you want to te...</td>\n",
              "      <td>0.962545</td>\n",
              "      <td>36.186142</td>\n",
              "      <td>what is the minimum required if you want to te...</td>\n",
              "      <td>0.897881</td>\n",
              "      <td>35.786514</td>\n",
              "      <td>False</td>\n",
              "      <td>0.811828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how was temüjin kept imprisoned by the tayichi...</td>\n",
              "      <td>0.013612</td>\n",
              "      <td>76.901253</td>\n",
              "      <td>how was temüjin kept imprisoned by the tayichi...</td>\n",
              "      <td>0.069142</td>\n",
              "      <td>107.826492</td>\n",
              "      <td>False</td>\n",
              "      <td>0.357724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what did herr gott, dich loben wir become know...</td>\n",
              "      <td>0.996422</td>\n",
              "      <td>89.606651</td>\n",
              "      <td>what did herr gott, dich loben wir become know...</td>\n",
              "      <td>0.125517</td>\n",
              "      <td>74.550781</td>\n",
              "      <td>True</td>\n",
              "      <td>0.878613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  original_score  \\\n",
              "0  what came into force after the new constitutio...        0.005043   \n",
              "1  what is the first major city in the stream of ...        0.567084   \n",
              "2  what is the minimum required if you want to te...        0.962545   \n",
              "3  how was temüjin kept imprisoned by the tayichi...        0.013612   \n",
              "4  what did herr gott, dich loben wir become know...        0.996422   \n",
              "\n",
              "   original_perplexity                                counterfactual_text  \\\n",
              "0           103.854469  what came into force before the new constituti...   \n",
              "1           119.536102  what is the first major city in the stream of ...   \n",
              "2            36.186142  what is the minimum required if you want to te...   \n",
              "3            76.901253  how was temüjin kept imprisoned by the tayichi...   \n",
              "4            89.606651  what did herr gott, dich loben wir become know...   \n",
              "\n",
              "   counterfactual_score  counterfactual_perplexity  found_flip  \\\n",
              "0              0.005943                 104.258759       False   \n",
              "1              0.003544                  76.490227        True   \n",
              "2              0.897881                  35.786514       False   \n",
              "3              0.069142                 107.826492       False   \n",
              "4              0.125517                  74.550781        True   \n",
              "\n",
              "   levenshtein_similarity_score  \n",
              "0                      0.966667  \n",
              "1                      0.494845  \n",
              "2                      0.811828  \n",
              "3                      0.357724  \n",
              "4                      0.878613  "
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_output.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.to_csv(f\"./output/fizlenaive-output-{dataset}-new-2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FIZLE guided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = {\"model\": \"gpt-4-turbo\"}\n",
        "df_output = get_output(df_input, generate_naive_fizle_counterfactual, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_output.to_csv(f\"./output/fizleguided-output-{dataset}.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
