{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fizle_task = \"sentiment analysis on the SST-2 dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIZLE\n",
    "\n",
    "### Naive\n",
    "\n",
    "Prompt:\n",
    "In the task of <task on task-dataset>, a trained black-box classifier correctly predicted the label ‘<yi>’ for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from ‘<yi>’ to ‘<ycf >’. Use the following definition of ‘counterfactual explanation’: “A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\\n—\\nText: <xi>.\n",
    "\n",
    "### Guided\n",
    "\n",
    "Prompt for step 1:\n",
    "\n",
    "In the task of <task on task-dataset>, a trained black-box classifier correctly predicted the label ‘<yi>’ for the following text. Explain why the model predicted the ‘<yi>’ label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list.\\n—\\nText: <xi>\n",
    "\n",
    "Prompt for step 2:\n",
    "\n",
    "Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from ‘<yi>’ to ‘<ycf >’. Use the following definition of ‘counterfactual explanation’: “A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def call_openai_api(system_prompt, model):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ]\n",
    "    )\n",
    "    output = completion.choices[0].message.content\n",
    "    return output\n",
    "\n",
    "def generate_naive_fizle_counterfactual(original_text, args):\n",
    "    original_score, model = args[\"original_score\"], args[\"model\"]\n",
    "    original_label = 1 if original_score >= 0.5 else 0\n",
    "    cf_label = 0 if original_label == 1 else 1\n",
    "\n",
    "    system_prompt = f\"\"\"In the task of {fizle_task}, a trained black-box classifier correctly predicted the label '{original_label}' for the following text. Generate a counterfactual explanation by making minimal changes to the input text, so that the label changes from '{original_label}' to '{cf_label}'. Use the following definition of 'counterfactual explanation': \"A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.\" Enclose the generated text within <new> tags.\n",
    "    -\n",
    "    Text: {original_text}\"\"\"\n",
    "\n",
    "    correct_output_format = False\n",
    "    for i in range(10):\n",
    "        print(f\"attempt: {i + 1}\")\n",
    "        output = call_openai_api(system_prompt, model)\n",
    "        counterfactual_text = re.search(\"<new>(.*?)</new>\", output).group(1)\n",
    "        if counterfactual_text:\n",
    "            correct_output_format = True\n",
    "            break\n",
    "\n",
    "    if not correct_output_format:\n",
    "        print(\"Failed to generate counterfactual surrounded by <new> tags\")\n",
    "        counterfactual_text = output[5:-6]\n",
    "\n",
    "    return counterfactual_text\n",
    "\n",
    "def generate_guided_fizle_counterfactual(original_text, args):\n",
    "    original_score, model = args[\"original_score\"], args[\"model\"]\n",
    "    original_label = 1 if original_score >= 0.5 else 0\n",
    "    cf_label = 0 if original_label == 1 else 1\n",
    "    system_prompt = \"\"\n",
    "\n",
    "    # 1. Find important words\n",
    "    step1_system_prompt = \" \".join([\n",
    "        f\"In the task of {fizle_task}, a trained black-box classifier correctly predicted the label '{original_label}' for the following text.\",\n",
    "        f\"Explain why the model predicted the '{original_label}' label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list.\",\n",
    "        f\"\\n-\\nText: {original_text}\",\n",
    "        f\"\\nImportant words identified: \"\n",
    "    ])\n",
    "    system_prompt += step1_system_prompt\n",
    "    important_words = call_openai_api(step1_system_prompt, model)\n",
    "    system_prompt += important_words + \"\\n\"\n",
    "\n",
    "    # 2. Generate the final counterfactual\n",
    "    correct_output_format = False\n",
    "    for i in range(10):\n",
    "        step2_system_prompt = \" \".join([\n",
    "            f\"Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from '{original_label}' to '{cf_label}'.\",\n",
    "            f\"Use the following definition of 'counterfactual explanation': 'A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.'\",\n",
    "            f\"Enclose the generated text within <new> tags.\"\n",
    "        ])\n",
    "        final_system_prompt = system_prompt + step2_system_prompt\n",
    "        print(f\"final_system_prompt: {final_system_prompt}\")\n",
    "        step2_output = call_openai_api(final_system_prompt, model)\n",
    "        counterfactual_text = re.search(\"<new>(.*?)</new>\", step2_output).group(1)\n",
    "        if counterfactual_text:\n",
    "            correct_output_format = True\n",
    "            break\n",
    "\n",
    "    if not correct_output_format:\n",
    "        print(\"Failed to generate counterfactual surrounded by <new> tags\")\n",
    "        counterfactual_text = output[5:-6]\n",
    "\n",
    "    return counterfactual_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the naive version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I hate this movie!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text = \"I love this movie!\"\n",
    "args = {\"original_score\": 0.9, \"model\": \"gpt-4-turbo\"}\n",
    "counterfactual_text = generate_naive_fizle_counterfactual(original_text, args)\n",
    "counterfactual_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the guided version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label '1' for the following text. Explain why the model predicted the '1' label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list. \n",
      "-\n",
      "Text: Marvelous, merry and, yes, melancholy film. \n",
      "Important words identified: Marvelous, merry\n",
      "Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from '1' to '0'. Use the following definition of 'counterfactual explanation': 'A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.' Enclose the generated text within <new> tags.\n",
      "Original:           : Marvelous, merry and, yes, melancholy film.\n",
      "Counterfactual:     : Terrible, dreary and, yes, melancholy film.\n",
      "\n",
      "final_system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label '1' for the following text. Explain why the model predicted the '1' label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list. \n",
      "-\n",
      "Text: Arnold's jump from little screen to big will leave frowns on more than a few faces. \n",
      "Important words identified: frowns\n",
      "Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from '1' to '0'. Use the following definition of 'counterfactual explanation': 'A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.' Enclose the generated text within <new> tags.\n",
      "Original:           : Arnold's jump from little screen to big will leave frowns on more than a few faces.\n",
      "Counterfactual:     : Arnold's jump from little screen to big will leave smiles on more than a few faces.\n",
      "\n",
      "final_system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label '1' for the following text. Explain why the model predicted the '1' label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list. \n",
      "-\n",
      "Text: The movie makes absolutely no sense. \n",
      "Important words identified: absolutely, no, sense\n",
      "Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from '1' to '0'. Use the following definition of 'counterfactual explanation': 'A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.' Enclose the generated text within <new> tags.\n",
      "Original:           : The movie makes absolutely no sense.\n",
      "Counterfactual:     : The movie makes absolutely total sense.\n",
      "\n",
      "final_system_prompt: In the task of sentiment analysis on the SST-2 dataset, a trained black-box classifier correctly predicted the label '1' for the following text. Explain why the model predicted the '1' label by identifying the words in the input that caused the label. List ONLY the words as a comma separated list. \n",
      "-\n",
      "Text: It's a movie -- and an album -- you won't want to miss. \n",
      "Important words identified: won't want to miss\n",
      "Generate a counterfactual explanation for the original text by ONLY changing a minimal set of the words you identified, so that the label changes from '1' to '0'. Use the following definition of 'counterfactual explanation': 'A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome.' Enclose the generated text within <new> tags.\n",
      "Original:           : It's a movie -- and an album -- you won't want to miss.\n",
      "Counterfactual:     : It's a movie -- and an album -- you won't want to see.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Marvelous, merry and, yes, melancholy film.\",\n",
    "    \"Arnold's jump from little screen to big will leave frowns on more than a few faces.\",\n",
    "    \"The movie makes absolutely no sense.\",\n",
    "    \"It's a movie -- and an album -- you won't want to miss.\"\n",
    "]\n",
    "\n",
    "for original_text in texts:\n",
    "    args = {\"original_score\": 0.9, \"model\": \"gpt-4-turbo\"}\n",
    "    counterfactual_text = generate_guided_fizle_counterfactual(original_text, args)\n",
    "    label_width = 20\n",
    "    original_label = \"Original:\".ljust(label_width)\n",
    "    counterfactual_label = \"Counterfactual:\".ljust(label_width)\n",
    "    print(f\"{original_label}: {original_text}\")\n",
    "    print(f\"{counterfactual_label}: {counterfactual_text}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
